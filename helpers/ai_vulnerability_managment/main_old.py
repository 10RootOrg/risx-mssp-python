#!/usr/bin/env python3
import os
import sys

# Get the absolute path of this script
script_path = os.path.abspath(__file__)
script_dir = os.path.dirname(script_path)
main_dir = os.path.abspath(os.path.join(script_dir, "../.."))
os.chdir(main_dir)
sys.path.insert(0, main_dir)
print(f"Current Working Directory: {os.getcwd()}")

import additionals.mysql_functions
import openai
import json
import additionals.logger
import additionals.funcs

# Configuration Variables
API_KEY = ""  # Replace with your actual API key
MODEL = "gpt-4o-mini-search-preview"  # Or "gpt-4-turbo", "gpt-4", "gpt-3.5-turbo"
PRODUCTS = []
MAX_TOKENS = 4096  # Ensure model can accept a lot of tokens
MIN_CVSS_SCORE = 8
PROMPT = """Retrieve CVEs from the past month with a CVSS score above min-cvss-score_to_check_in_prompt that are relevant to the following devices:
Products: products_to_check_in_prompt
Return the data in JSON format with a maximum of 3 CVEs per response. If there are more than 3 CVEs available, prepend true before the JSON; otherwise, prepend false.

Each CVE entry should have the following fields:

CVE ID – The identifier of the CVE
CVSS Score – The severity rating
Affected Device – The impacted system
YARA Rule – A YARA rule for detecting the vulnerability
Sigma Rule – A Sigma rule for detecting the vulnerability
Mitigation Tips – Recommended actions to mitigate the vulnerability
Generate YARA and Sigma rules specific to each CVE. Return only the JSON without additional explanations."""

JSON_OUTPUT_PATH = os.path.join("response_folder", "CVE_AI_MANAGMENT_RESULTS.json") # Default path, can be overridden

current_cve_index = 0
all_cves = []
client = ""

def setup_global_variables(config, logger):
    global API_KEY, MODEL, MAX_TOKENS, PROMPT, PRODUCTS, JSON_OUTPUT_PATH, client
    API_KEY = config['ClientData']['API']['AiManagement']
    ai_config = config["General"]["IntervalConfigurations"]["AiManagement"]
    if(ai_config["MODEL"] != ""):
        MODEL = ai_config["MODEL"]
    if(ai_config["MAX_TOKENS"]):
        MAX_TOKENS = ai_config["MAX_TOKENS"]
    if(ai_config["MIN_CVSS_SCORE"]):
        MAX_TOKENS = ai_config["MIN_CVSS_SCORE"]
    if(ai_config["PROMPT"] != ""):
        PROMPT = ai_config["PROMPT"]
    if(ai_config["PRODUCTS"] != []):
        PRODUCTS = ai_config["PRODUCTS"]

    PROMPT = PROMPT.replace("min-cvss-score_to_check_in_prompt", str(MIN_CVSS_SCORE)).replace("products_to_check_in_prompt", ", ".join(PRODUCTS))
    logger.info("Prompt:\n" + PROMPT)
    
    client = openai.OpenAI(api_key=API_KEY)  # Initialize the client


def query_gpt(logger):
    """Send prompt to GPT and retrieve the CVEs with logging."""
    
    try:
        logger.info("Sending query to GPT model...")

        response = client.chat.completions.create(
            model=MODEL,
            messages=[
                {"role": "system", "content": "You are an expert in cybersecurity providing CVE details."},
                {"role": "user", "content": PROMPT}
            ],
            max_tokens=4096
        )

        # Ensure the response is valid
        if not response or not response.choices:
            logger.error("GPT response is empty or malformed.")
            return None

        # Extract response text safely
        response_text = response.choices[0].message.content.strip()

        # Log the full GPT response
        logger.info(f"FULL GPT Response:\n{response_text}")

        return response_text

    except openai.APIConnectionError:
        logger.error("Failed to connect to OpenAI API. Check internet connection.")
        return None

    except openai.OpenAIError as e:
        logger.error(f"OpenAI API error: {str(e)}")
        return None

    except Exception as e:
        logger.error(f"Unexpected error in query_gpt: {str(e)}")
        return None


def parse_response(response_text):
    """Parse the response and extract CVEs."""
    global all_cves
    response_text = response_text.strip()
    
    if response_text.startswith("true"):
        json_data = response_text[4:].strip()
        prepend_true = True
    elif response_text.startswith("false"):
        json_data = response_text[5:].strip()
        prepend_true = False
    else:
        # Handle case where response doesn't have expected prefix
        logger.warning("Response doesn't start with 'true' or 'false', attempting to parse as JSON directly")
        json_data = response_text
        prepend_true = False
    
    try:
        cve_list = json.loads(json_data)
        all_cves.extend(cve_list)
        return prepend_true
    except json.JSONDecodeError as e:
        logger.error(f"Failed to parse JSON response: {str(e)}")
        logger.debug(f"Problematic JSON data: {json_data}")
        return False

def get_next_cves(logger):
    """Retrieve the next batch of CVEs."""
    global current_cve_index, all_cves
    
    # Check if we have CVEs in our existing cache
    if current_cve_index < len(all_cves):
        next_cves = all_cves[current_cve_index:current_cve_index + 3]
        current_cve_index += len(next_cves)
        prepend_true = current_cve_index < len(all_cves)
        return prepend_true, json.dumps(next_cves, indent=4)
    
    # If we're here, we need to fetch more CVEs
    response_text = query_gpt(logger)
    if not response_text:
        logger.error("Failed to get response from GPT")
        return False, json.dumps([])
    
    # Parse the new response
    more_available = parse_response(response_text)
    
    # Get the newly added CVEs
    if current_cve_index < len(all_cves):
        next_cves = all_cves[current_cve_index:current_cve_index + 3]
        current_cve_index += len(next_cves)
        return more_available, json.dumps(next_cves, indent=4)
    else:
        # No new CVEs were added
        logger.info("No more CVEs available")
        return False, json.dumps([])

def save_json_to_file(cve_data, logger):
    """Save the CVE data to a JSON file, combining with existing data if the file exists."""
    try:
        # Parse the current JSON data
        new_cves = json.loads(cve_data)
        
        # Check if file exists and has content
        if os.path.exists(JSON_OUTPUT_PATH) and os.path.getsize(JSON_OUTPUT_PATH) > 0:
            logger.info(f"JSON file exists at {JSON_OUTPUT_PATH}, combining with existing data...")
            with open(JSON_OUTPUT_PATH, 'r') as file:
                existing_data = json.load(file)
                
            # Combine new data with existing data (new data at the top)
            combined_data = new_cves + existing_data
        else:
            logger.info(f"Creating new JSON file at {JSON_OUTPUT_PATH}")
            combined_data = new_cves
        
        # Write the combined data back to the file
        with open(JSON_OUTPUT_PATH, 'w') as file:
            json.dump(combined_data, file, indent=4)
            
        logger.info(f"Successfully saved data to {JSON_OUTPUT_PATH}")
        return True
    except Exception as e:
        logger.error(f"Error saving JSON data: {str(e)}")
        return False

if __name__ == "__main__":
    logger = additionals.logger.setup_logger("alerts_vuln_cve_managment_helper.log")
    env_dict = additionals.funcs.read_env_file(logger)
    connection = additionals.mysql_functions.setup_mysql_connection(env_dict, logger)
    config_data = json.loads(additionals.mysql_functions.execute_query(connection, "SELECT config FROM configjson LIMIT 1", logger)[0][0])
    setup_global_variables(config_data, logger)
    
    # Check for command line argument to set output path
    if len(sys.argv) > 1:
        JSON_OUTPUT_PATH = sys.argv[1]
        logger.info(f"Output path set from command line: {JSON_OUTPUT_PATH}")
    
    prepend_true, cve_json = get_next_cves(logger)
    logger.info("true" if prepend_true else "false")
    logger.info("Full CVE before save:" + str(cve_json))
    
    # Save JSON data to file
    save_result = save_json_to_file(cve_json, logger)
    if save_result:
        logger.info(f"CVE data successfully saved to {JSON_OUTPUT_PATH}")
    else:
        logger.error(f"Failed to save CVE data to {JSON_OUTPUT_PATH}")