import pandas as pd
from pyvelociraptor import api_pb2
from pyvelociraptor import api_pb2_grpc
import json
import time
import modules.Velociraptor.VelociraptorScript
import re
import concurrent.futures

def run_generic_client_info(general_settings, logger):
    """
    Runs the Generic.Client.Info artifact and returns the operating system information.
    
    Args:
        general_settings: Dictionary containing configuration settings
        logger: Logger object for logging messages
    
    Returns:
        list: List of strings containing OS information for CVE checking
    """
    try:
        # Set artifact parameters
        artifact_name = "Generic.Client.Info"
        timeout = general_settings["TimeForProductsDetectionInSeconds"]
        
        # Set resource limits
        expire_time = general_settings["TimeForProductsDetectionInSeconds"]
        cpu_limit = 50
        max_bytes_uploaded = 100000000
        max_rows = 1000000
        
        logger.info(f"Starting Generic.Client.Info artifact with {timeout}s timeout")
        
        # Setup connection
        channel = modules.Velociraptor.VelociraptorScript.setup_connection(logger)
        if not channel:
            logger.error("Failed to establish connection")
            return []
            
        stub = api_pb2_grpc.APIStub(channel)
        
        # Create hunt query
        spec = f"dict(`{artifact_name}`=dict())"
        query = f"LET collection = hunt(description='API Hunt:{artifact_name}', artifacts='{artifact_name}', spec={spec}, expires=now() + {expire_time}, timeout={timeout}, max_rows={max_rows}, max_bytes={max_bytes_uploaded}, cpu_limit={cpu_limit}) SELECT HuntId FROM collection"
        
        # Launch hunt
        hunt_id = None
        request = api_pb2.VQLCollectorArgs(Query=[api_pb2.VQLRequest(VQL=query)])
        
        for response in stub.Query(request):
            if response.Response and response.Response != "[]":
                parsed_json = json.loads(response.Response)
                hunt_id = parsed_json[0]["HuntId"]
                logger.info(f"Hunt started with ID: {hunt_id}")
                break
        
        if not hunt_id:
            logger.error("Failed to get hunt ID")
            channel.close()
            return []
        
        # Wait for hunt to collect some data
        logger.info("Waiting for hunt to collect data...")
        time.sleep(10)
        
        # Attempt to collect results
        max_attempts = 5
        for attempt in range(1, max_attempts + 1):
            logger.info(f"Collection attempt {attempt}/{max_attempts}")
            
            # Query for results
            results_query = f"SELECT * FROM hunt_results(hunt_id='{hunt_id}')"
            results_request = api_pb2.VQLCollectorArgs(
                Query=[api_pb2.VQLRequest(VQL=results_query)]
            )
            
            all_rows = []
            try:
                for response in stub.Query(results_request):
                    if response.Response:
                        rows = json.loads(response.Response)
                        if rows:
                            all_rows.extend(rows)
            except Exception as e:
                logger.warning(f"Error in collection attempt {attempt}: {str(e)}")
            
            if all_rows:
                logger.info(f"Successfully collected {len(all_rows)} rows of OS info")
                
                # Extract OS information
                os_list = extract_os_info(all_rows, logger)
                logger.info("OS from velociraptor:" + str(os_list))
                channel.close()
                return os_list
                
            # Wait before next attempt
            if attempt < max_attempts:
                logger.info("Waiting 30 seconds before next collection attempt...")
                time.sleep(30)
        
        logger.warning("Maximum collection attempts reached")
        channel.close()
        return []
        
    except Exception as e:
        error_msg = f"Error running Generic.Client.Info artifact: {str(e)}"
        logger.error(error_msg)
        return []

def extract_os_info(data, logger):
    """
    Extracts operating system information from Generic.Client.Info results.
    
    Args:
        data: List of dictionaries containing client info data
        logger: Logger object for logging messages
    
    Returns:
        list: List of strings containing OS information for CVE checking
    """
    logger.info("Extracting OS information from Generic.Client.Info results")
    
    os_versions = {}
    
    for row in data:
        try:
            # First check if Platform and PlatformVersion fields are available (preferred)
            platform = row.get("Platform", "")
            platform_version = row.get("PlatformVersion", "")
            
            # If Platform fields not available, fall back to OS and Version
            os_name = row.get("OS", "")
            os_version = row.get("Version", "")
            
            # Determine which set of fields to use
            if platform and platform_version:
                logger.info(f"Using Platform data: {platform} {platform_version}")
                primary_name = platform
                primary_version = platform_version
            elif os_name:
                logger.info(f"Using OS data: {os_name} {os_version}")
                primary_name = os_name
                primary_version = os_version
            else:
                # Skip if no OS/Platform info
                continue
                
            # Standardize OS name
            if "windows" in primary_name.lower():
                # Handle Windows OS
                if "11" in primary_version or "11" in primary_name:
                    std_name = "Microsoft Windows 11"
                    # Check for edition info
                    if "pro" in primary_name.lower() or "pro" in primary_version.lower():
                        std_name += " Pro"
                    elif "enterprise" in primary_name.lower() or "enterprise" in primary_version.lower():
                        std_name += " Enterprise"
                    elif "home" in primary_name.lower() or "home" in primary_version.lower():
                        std_name += " Home"
                elif "10" in primary_version or "10" in primary_name:
                    std_name = "Microsoft Windows 10"
                    # Check for edition info
                    if "pro" in primary_name.lower() or "pro" in primary_version.lower():
                        std_name += " Pro"
                    elif "enterprise" in primary_name.lower() or "enterprise" in primary_version.lower():
                        std_name += " Enterprise"
                    elif "home" in primary_name.lower() or "home" in primary_version.lower():
                        std_name += " Home"
                elif "server" in primary_name.lower() or "server" in primary_version.lower() or "2016" in primary_version or "2019" in primary_version or "2022" in primary_version:
                    std_name = "Microsoft Windows Server"
                    # Extract server version
                    server_ver_match = re.search(r'(20\d\d)', primary_version)
                    if not server_ver_match:
                        server_ver_match = re.search(r'(20\d\d)', primary_name)
                    
                    if server_ver_match:
                        std_name += f" {server_ver_match.group(1)}"
                    else:
                        std_name += " 2016"  # Default if version not found
                else:
                    std_name = f"Microsoft Windows {primary_version}"
            elif "linux" in primary_name.lower() or "ubuntu" in primary_name.lower():
                # Handle Linux OS
                if "ubuntu" in primary_name.lower() or "ubuntu" in primary_version.lower():
                    std_name = "Ubuntu"
                    # Try to extract Ubuntu version
                    ubuntu_ver_match = re.search(r'(\d+\.\d+)', primary_version)
                    if ubuntu_ver_match:
                        std_name += f" {ubuntu_ver_match.group(1)}"
                else:
                    std_name = primary_name
            elif "macos" in primary_name.lower() or "darwin" in primary_name.lower():
                # Handle macOS
                std_name = "Apple macOS"
                # Try to extract macOS version
                mac_ver_match = re.search(r'(\d+\.\d+)', primary_version)
                if mac_ver_match:
                    std_name += f" {mac_ver_match.group(1)}"
            else:
                # Default for other OS types
                std_name = primary_name
            
            # Clean up build information to get cleaner version numbers
            clean_version = primary_version
            build_match = re.search(r'(\d+\.\d+(?:\.\d+)?)', primary_version)
            if build_match:
                clean_version = build_match.group(1)
                
            # Parse version for comparison
            version_parts = re.findall(r'(\d+)(?:\.|$)', clean_version)
            if not version_parts:
                parsed_version = [999, 999, 999]  # Default high version if no version found
            else:
                parsed_version = [int(part) for part in version_parts]
                
            # Ensure at least 3 components
            while len(parsed_version) < 3:
                parsed_version.append(0)
                
            # Check if this OS is already in our dictionary
            if std_name in os_versions:
                current_version = os_versions[std_name]["parsed"]
                
                # Compare versions to keep the lower one
                is_lower = False
                for i in range(min(len(current_version), len(parsed_version))):
                    if parsed_version[i] < current_version[i]:
                        is_lower = True
                        break
                    elif parsed_version[i] > current_version[i]:
                        break
                        
                if is_lower:
                    os_versions[std_name] = {
                        "version": clean_version,
                        "full_version": primary_version,
                        "parsed": parsed_version
                    }
            else:
                # First time seeing this OS
                os_versions[std_name] = {
                    "version": clean_version,
                    "full_version": primary_version,
                    "parsed": parsed_version
                }
                
        except Exception as e:
            logger.warning(f"Error processing OS row: {str(e)}")
            logger.warning(f"Problematic row data: {row}")
    
    # Convert to string format for CPE checking
    result = []
    for name, version_info in os_versions.items():
        version = version_info["version"]
        if version:
            result.append(f"{name} {version}")
        else:
            result.append(f"{name} None")
    
    return result

def run_windows_sys_programs(general_settings, logger):
    """
    Runs the Windows.Sys.Programs artifact and returns the results.
    
    Args:
        general_settings: Dictionary containing configuration settings
        logger: Logger object for logging messages
    
    Returns:
        list: List of strings containing program information for CVE checking
    """
    try:
        # Set artifact parameters
        artifact_name = "Windows.Sys.Programs"
        timeout = general_settings["TimeForProductsDetectionInSeconds"]
        
        # Set resource limits
        expire_time = general_settings["TimeForProductsDetectionInSeconds"]
        cpu_limit = 50
        max_bytes_uploaded = 100000000
        max_rows = 1000000
        
        logger.info(f"Starting Windows.Sys.Programs artifact with {timeout}s timeout")
        
        # Setup connection
        channel = modules.Velociraptor.VelociraptorScript.setup_connection(logger)
        if not channel:
            logger.error("Failed to establish connection")
            return []
            
        stub = api_pb2_grpc.APIStub(channel)
        
        # Create hunt query
        spec = f"dict(`{artifact_name}`=dict())"
        query = f"LET collection = hunt(description='API Hunt:{artifact_name}', artifacts='{artifact_name}', spec={spec}, expires=now() + {expire_time}, timeout={timeout}, max_rows={max_rows}, max_bytes={max_bytes_uploaded}, cpu_limit={cpu_limit}) SELECT HuntId FROM collection"
        
        # Launch hunt
        hunt_id = None
        request = api_pb2.VQLCollectorArgs(Query=[api_pb2.VQLRequest(VQL=query)])
        
        for response in stub.Query(request):
            if response.Response and response.Response != "[]":
                parsed_json = json.loads(response.Response)
                hunt_id = parsed_json[0]["HuntId"]
                logger.info(f"Hunt started with ID: {hunt_id}")
                break
        
        if not hunt_id:
            logger.error("Failed to get hunt ID")
            channel.close()
            return []
        
        # Wait for hunt to collect some data
        logger.info("Waiting for hunt to collect data...")
        time.sleep(10)
        
        # Attempt to collect results
        max_attempts = 5
        for attempt in range(1, max_attempts + 1):
            logger.info(f"Collection attempt {attempt}/{max_attempts}")
            
            # Query for results
            results_query = f"SELECT * FROM hunt_results(hunt_id='{hunt_id}')"
            results_request = api_pb2.VQLCollectorArgs(
                Query=[api_pb2.VQLRequest(VQL=results_query)]
            )
            
            all_rows = []
            try:
                for response in stub.Query(results_request):
                    if response.Response:
                        rows = json.loads(response.Response)
                        if rows:
                            all_rows.extend(rows)
            except Exception as e:
                logger.warning(f"Error in collection attempt {attempt}: {str(e)}")
            
            if all_rows:
                logger.info(f"Successfully collected {len(all_rows)} rows")
                
                # Create DataFrame from results
                data_df = pd.DataFrame(all_rows)
                
                # Log summary information
                logger.info(f"Collected data summary:")
                logger.info(f"Total rows: {len(all_rows)}")
                logger.info(f"Columns: {list(data_df.columns)}")
                
                # Extract unique software with oldest versions
                logger.info(data_df)
                software_list = extract_software_for_cve_check(data_df, logger)
                logger.info("Products from velociraptor:" + str(software_list))
                channel.close()
                return software_list
                
            # Wait before next attempt
            if attempt < max_attempts:
                logger.info("Waiting 30 seconds before next collection attempt...")
                time.sleep(30)
        
        logger.warning("Maximum collection attempts reached")
        channel.close()
        return []
        
    except Exception as e:
        error_msg = f"Error running Windows.Sys.Programs artifact: {str(e)}"
        logger.error(error_msg)
        return []
    
def extract_software_for_cve_check(data, logger, is_dataframe=True):
    """
    Extracts unique software names and versions for CVE checking,
    keeping only the oldest version of each product and excluding certain types.
    
    Args:
        data: Either a DataFrame from run_windows_sys_programs or a list of software strings
        logger: Logger object for logging messages
        is_dataframe: Boolean indicating whether data is a DataFrame (True) or a list (False)
        
    Returns:
        list: List of strings in format "DisplayName DisplayVersion" for CVE checking
    """
    logger.info("Starting extraction of software for CVE checking")
    
    # Comprehensive exclusion list
    excluded_keywords = [
        # System and development components
        "Microsoft .NET", "Redistributable", "Targeting Pack", "Framework", "ClickOnce",
        "SDK", "Runtime", "Visual Studio", "AppHost", "Update", "Installer", "Manifest",
        "Windows Subsystem", "Windows SDK", "WinRT", "Icecap", "vcpp", "base_", "Collection",
        
        # Additional exclusions
        "Package", "Python Package", "Python 2.7 Package", 
        "Driver", "Library", "Component", "Service",
        "Universal CRT", "Windows App Certification", "Click-to-Run",
        "PyQt4", "Application Verifier", "Visual C++", "Microsoft ASP.NET",
        "Microsoft System", "Debugger", "Tools", "Utilities", "WPT", "USB", "python", "Python", "vs_", "windows_"
    ]
    
    software_list = []
    
    # Process DataFrame input
    if is_dataframe:
        # Filter for rows that have values in critical fields
        logger.info(f"Processing DataFrame input with {len(data)} rows")
        mask = (
            data['DisplayName'].notna() & 
            data['DisplayName'] != ''
        )
        
        # Get only entries with display names
        software_df = data[mask].copy()
        
        if software_df.empty:
            logger.warning("No valid software entries found in DataFrame")
            return []
            
        logger.info(f"Found {len(software_df)} entries with valid display names")
        
        # Create a list of name+version strings
        for _, row in software_df.iterrows():
            name = row['DisplayName']
            version = row.get('DisplayVersion', '')
            if not version:
                version = 'None'
            software_list.append((name, version))
    else:
        # Input is already a list of strings
        logger.info(f"Processing list input with {len(data)} items")
        
        for item in data:
            # Skip empty entries
            if not item or item.isspace():
                continue
            
            # Use regex to extract the version from the end
            match = re.search(r'(.+?)\s+(\d+(?:\.\d+)*(?:[-\.][a-zA-Z0-9]+)*)\s*$', item)
            
            if match:
                name, version = match.groups()
            else:
                # Fallback to simple splitting on the last space
                parts = item.rsplit(' ', 1)
                if len(parts) >= 2 and re.match(r'\d', parts[-1]):
                    name, version = parts
                else:
                    name = item
                    version = 'None'
            
            software_list.append((name.strip(), version.strip()))
    
    # Dictionary to store software name -> version mappings
    software_versions = {}
    duplicates_found = 0
    
    # Define function for standardizing software names
    def standardize_name(name):
        # Remove architecture information
        name = re.sub(r'\s*\((x86|x64|64-bit|32-bit)\)', '', name)
        name = re.sub(r'\s*x(86|64)\b', '', name)
        
        # Handle browser standardization
        if "Chrome" in name and "Edge" not in name:
            return "Google Chrome"
        if "Firefox" in name:
            return "Mozilla Firefox"
        if "Edge" in name:
            return "Microsoft Edge"
        
        return name.strip()
    
    # Define function to parse version strings
    def parse_version(version_str):
        """Parse a version string into a list of integers for comparison."""
        if version_str.lower() == 'none':
            return [999, 999, 999, 999]  # Treat 'None' as highest version
        
        # Extract all numeric parts
        parts = re.findall(r'(\d+)(?:\.|$|-)', version_str)
        
        # Convert to integers with zero-padding
        numeric_parts = [int(part) for part in parts]
        
        # Ensure at least 4 components
        while len(numeric_parts) < 4:
            numeric_parts.append(0)
            
        return numeric_parts
    
    # Process each software item
    for name, version in software_list:
        # Skip if name is empty
        if not name:
            continue
        
        # Standardize the name
        standardized_name = standardize_name(name)
        
        # Check if we've seen this software before
        if standardized_name in software_versions:
            # Found a duplicate
            duplicates_found += 1
            
            current_version = software_versions[standardized_name]
            
            # Skip if version is 'None'
            if version.lower() == 'none':
                continue
                
            # If current stored version is 'None', replace it
            if current_version.lower() == 'none':
                software_versions[standardized_name] = version
                continue
            
            # Parse both versions for comparison
            current_parsed = parse_version(current_version)
            new_parsed = parse_version(version)
            
            # Compare version numbers - we want to keep the OLDER version
            is_older = False
            for i in range(min(len(current_parsed), len(new_parsed))):
                if new_parsed[i] < current_parsed[i]:
                    is_older = True
                    break
                elif new_parsed[i] > current_parsed[i]:
                    break
            
            # Keep the older version (smaller values)
            if is_older:
                logger.debug(f"Replacing version for {standardized_name}: {current_version} -> {version} (older)")
                software_versions[standardized_name] = version
        else:
            # First time seeing this software
            software_versions[standardized_name] = version
    
    # Convert the dictionary back to a list of "name version" strings
    result = [f"{name} {version}" for name, version in sorted(software_versions.items())]
    
    # Filter out excluded keywords
    original_count = len(result)
    filtered_result = [item for item in result if not any(keyword in item for keyword in excluded_keywords)]
    excluded_count = original_count - len(filtered_result)
    
    logger.info(f"Extraction complete: {len(filtered_result)} unique software found after filtering, {duplicates_found} duplicates handled, {excluded_count} items excluded")
    
    return filtered_result

def run_linux_debian_packages(general_settings, logger):
    """
    Runs the Linux.Debian.Packages artifact and returns the package information.
    
    Args:
        general_settings: Dictionary containing configuration settings
        logger: Logger object for logging messages
    
    Returns:
        list: List of strings containing Linux package information for CVE checking
    """
    try:
        # Set artifact parameters
        artifact_name = "Linux.Debian.Packages"
        timeout = general_settings["TimeForProductsDetectionInSeconds"]
        
        # Set resource limits
        expire_time = general_settings["TimeForProductsDetectionInSeconds"]
        cpu_limit = 50
        max_bytes_uploaded = 100000000
        max_rows = 1000000
        
        logger.info(f"Starting Linux.Debian.Packages artifact with {timeout}s timeout")
        
        # Setup connection
        channel = modules.Velociraptor.VelociraptorScript.setup_connection(logger)
        if not channel:
            logger.error("Failed to establish connection")
            return []
            
        stub = api_pb2_grpc.APIStub(channel)
        
        # Create hunt query
        spec = f"dict(`{artifact_name}`=dict())"
        query = f"LET collection = hunt(description='API Hunt:{artifact_name}', artifacts='{artifact_name}', spec={spec}, expires=now() + {expire_time}, timeout={timeout}, max_rows={max_rows}, max_bytes={max_bytes_uploaded}, cpu_limit={cpu_limit}) SELECT HuntId FROM collection"
        
        # Launch hunt
        hunt_id = None
        request = api_pb2.VQLCollectorArgs(Query=[api_pb2.VQLRequest(VQL=query)])
        
        for response in stub.Query(request):
            if response.Response and response.Response != "[]":
                parsed_json = json.loads(response.Response)
                hunt_id = parsed_json[0]["HuntId"]
                logger.info(f"Hunt started with ID: {hunt_id}")
                break
        
        if not hunt_id:
            logger.error("Failed to get hunt ID")
            channel.close()
            return []
        
        # Wait for hunt to collect some data
        logger.info("Waiting for hunt to collect data...")
        time.sleep(10)
        
        # Attempt to collect results
        max_attempts = 5
        for attempt in range(1, max_attempts + 1):
            logger.info(f"Collection attempt {attempt}/{max_attempts}")
            
            # Query for results
            results_query = f"SELECT * FROM hunt_results(hunt_id='{hunt_id}')"
            results_request = api_pb2.VQLCollectorArgs(
                Query=[api_pb2.VQLRequest(VQL=results_query)]
            )
            
            all_rows = []
            try:
                for response in stub.Query(results_request):
                    if response.Response:
                        rows = json.loads(response.Response)
                        if rows:
                            all_rows.extend(rows)
            except Exception as e:
                logger.warning(f"Error in collection attempt {attempt}: {str(e)}")
            
            if all_rows:
                logger.info(f"Successfully collected {len(all_rows)} rows of Linux package info")
                
                # Extract package information
                package_list = extract_linux_packages(all_rows, logger)
                logger.info(f"Linux packages from velociraptor: {len(package_list)} packages")
                channel.close()
                return package_list
                
            # Wait before next attempt
            if attempt < max_attempts:
                logger.info("Waiting 30 seconds before next collection attempt...")
                time.sleep(30)
        
        logger.warning("Maximum collection attempts reached")
        channel.close()
        return []
        
    except Exception as e:
        error_msg = f"Error running Linux.Debian.Packages artifact: {str(e)}"
        logger.error(error_msg)
        return []

def extract_linux_packages(data, logger):
    """
    Extracts Linux package information from Linux.Debian.Packages results.
    
    Args:
        data: List of dictionaries containing package data
        logger: Logger object for logging messages
    
    Returns:
        list: List of strings containing package information for CVE checking
    """
    logger.info("Extracting Linux package information")
    
    package_versions = {}
    
    # Process both deb packages and snap packages
    for row in data:
        try:
            # Check if this is a deb package or snap package
            if "Package" in row:
                # This is a deb package
                package_name = row.get("Package", "")
                package_version = row.get("Version", "")
                source = row.get("Source", "")  # Sometimes source name is different from package
            elif "Name" in row:
                # This is a snap package
                package_name = row.get("Name", "")
                package_version = row.get("Version", "")
                source = ""
            else:
                # Unknown format
                continue
                
            # Skip if no package name
            if not package_name:
                continue
                
            # Use source name if available and different from package name
            if source and source != package_name:
                std_name = source
            else:
                std_name = package_name
                
            # Parse version for comparison
            # Debian versions can be complex (e.g., 1.2.3-4ubuntu5)
            # Extract main version numbers for comparison
            version_parts = re.findall(r'(\d+)(?:\.|$)', package_version)
            if not version_parts:
                parsed_version = [999, 999, 999, 999]  # Default high version if no version found
            else:
                parsed_version = [int(part) for part in version_parts]
                
            # Ensure at least 4 components for comparison
            while len(parsed_version) < 4:
                parsed_version.append(0)
                
            # Check if this package is already in our dictionary
            if std_name in package_versions:
                current_version = package_versions[std_name]["parsed"]
                
                # Compare versions to keep the lower one
                is_lower = False
                for i in range(min(len(current_version), len(parsed_version))):
                    if parsed_version[i] < current_version[i]:
                        is_lower = True
                        break
                    elif parsed_version[i] > current_version[i]:
                        break
                        
                if is_lower:
                    package_versions[std_name] = {
                        "version": package_version,
                        "parsed": parsed_version
                    }
            else:
                # First time seeing this package
                package_versions[std_name] = {
                    "version": package_version,
                    "parsed": parsed_version
                }
                
        except Exception as e:
            logger.warning(f"Error processing package row: {str(e)}")
            
    # Convert to string format for CPE checking
    result = []
    for name, version_info in package_versions.items():
        version = version_info["version"]
        if version:
            result.append(f"{name} {version}")
        else:
            result.append(f"{name} None")
    
    return result

def get_products_auto(general_settings, logger):
    """
    Runs Windows.Sys.Programs, Generic.Client.Info, and Linux.Debian.Packages artifacts
    simultaneously and combines the results for CVE checking.
    
    Args:
        general_settings: Dictionary containing configuration settings
        logger: Logger object for logging messages
    
    Returns:
        list: List of strings in format "Name Version" for CVE checking
    """
    logger.info("Starting parallel collection of all artifacts for CVE checking")
    
    # Use ThreadPoolExecutor to run functions in parallel
    with concurrent.futures.ThreadPoolExecutor(max_workers=3) as executor:
        # Submit all three tasks to the executor
        windows_future = executor.submit(run_windows_sys_programs, general_settings, logger)
        os_future = executor.submit(run_generic_client_info, general_settings, logger)
        linux_future = executor.submit(run_linux_debian_packages, general_settings, logger)
        
        # Wait for all tasks to complete and get their results
        # as_completed waits for the futures to complete, but we're using .result() directly on the Future objects
        software_list = windows_future.result()
        os_list = os_future.result()
        linux_package_list = linux_future.result()
    
    
    # Combine the results
    combined_list = software_list + os_list + linux_package_list + software_list
    
    # Log the combined results
    logger.info(f"Combined results for CVE checking: {len(combined_list)} items")
    logger.info(f"OS entries: {len(os_list)}")
    logger.info(f"Windows software entries: {len(software_list)}")
    logger.info(f"Linux package entries: {len(linux_package_list)}")
    
    return combined_list