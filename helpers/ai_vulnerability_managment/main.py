#!/usr/bin/env python3
import os
import sys
import json
import traceback

# Get the absolute path of this script
script_path = os.path.abspath(__file__)
script_dir = os.path.dirname(script_path)
main_dir = os.path.abspath(os.path.join(script_dir, "../.."))
os.chdir(main_dir)
sys.path.insert(0, main_dir)
print(f"Current Working Directory: {os.getcwd()}")

import additionals.mysql_functions
import openai
import additionals.logger
import additionals.funcs
import additionals.elastic_api

# Configuration Variables
API_KEY = ""  # Replace with your actual API key
MODEL = "gpt-4o-search-preview"
PRODUCTS = []
MAX_TOKENS = 4096  # Ensure model can accept a lot of tokens
MIN_CVSS_SCORE = 8
FROM_THE_FOLLOWING_TIME = "1 days"
SYSTEM_PROMPT = """You are a cybersecurity expert providing real, verified CVE details. You must return structured, well-formed JSON without truncation.

Response Format Rules:

Always return data as an array of objects, even if only one CVE is available.
Prepend a boolean flag (true or false) to indicate if more CVEs exist.
Use exactly five exclamation marks (!!!!!) to separate the boolean from the JSON. No spaces, no extra text.
Strictly follow the expected JSON structure below:
true!!!!![
{
"CVE ID": "CVE-YYYY-NNNNN",
"CVSS Score": 9.8,
"Affected Device": "Product Name",
"YARA Rule": {
"name": "Rule Name",
"meta": { ... },
"strings": [ ... ],
"condition": "some condition"
},
"Sigma Rule": {
"title": "Sigma Rule Title",
"logsource": { ... },
"detection": { ... },
"level": "high"
},
"Mitigation Tips": [ "Step 1", "Step 2", "Step 3" ]
}
]

Strict Requirements:

No fabricated CVEs, no placeholders, no made-up data.
Only return verifiable vulnerabilities from official sources (e.g., MITRE, NVD).
Ensure JSON is valid, complete, and follows this structure exactly.
Do not include explanations, disclaimers, or any text outside the JSON.
Always indicate whether more CVEs exist (true!!!!! or false!!!!!).
Your job is to return real, actionable cybersecurity intelligenceâ€”nothing else."""

JSON_OUTPUT_PATH = os.path.join("response_folder", "CVE_AI_MANAGMENT_RESULTS.json") # Default path, can be overridden

current_cve_index = 0
all_cves = []
client = None

def setup_global_variables(config, logger):
    global API_KEY, MODEL, MAX_TOKENS, LIST_PROMPT, PRODUCTS, JSON_OUTPUT_PATH, client, MIN_CVSS_SCORE, FROM_THE_FOLLOWING_TIME
    try:
        API_KEY = config.get('ClientData', {}).get('API', {}).get('AiManagement', '')
        if not API_KEY:
            logger.warning("API key not found in configuration")
            
        ai_config = config.get("General", {}).get("IntervalConfigurations", {}).get("AiManagement", {})
        if not ai_config:
            logger.warning("AiManagement configuration not found")
            ai_config = {}
            
        if ai_config.get("MODEL"):
            MODEL = ai_config["MODEL"]
        if ai_config.get("MAX_TOKENS"):
            MAX_TOKENS = ai_config["MAX_TOKENS"]
        if ai_config.get("MIN_CVSS_SCORE"):
            MIN_CVSS_SCORE = ai_config["MIN_CVSS_SCORE"]
        if ai_config.get("PROMPT"):
            LIST_PROMPT = ai_config["PROMPT"]
        if ai_config.get("PRODUCTS"):
            PRODUCTS = ai_config["PRODUCTS"]
        if ai_config.get("FromTheFollowingTime"):
            FROM_THE_FOLLOWING_TIME = ai_config["FromTheFollowingTime"]

        if not (PRODUCTS):
            LIST_PROMPT = """Retrieve CVEs from the past {from_time_to_check_in_prompt} with a CVSS score above {min_cvss_score_to_check_in_prompt}.
    Return the data in JSON format with a maximum of 1 CVEs per response. If more than 1 CVEs are available, prepend true before the JSON; otherwise, prepend false. Add it as the boolean and then the JSON with the "!!!!!" operator between them, without anything else in between.

    Each CVE entry should have the following fields:
    - CVE ID: The identifier of the CVE.
    - CVSS Score: The severity rating.
    - Affected Device: The impacted system.
    - YARA Rule: A serialized JSON object containing a YARA rule for detecting the vulnerability.
    - Sigma Rule: A serialized JSON object containing a Sigma rule for detecting the vulnerability.
    - Mitigation Tips: Recommended actions to mitigate the vulnerability.

    Return only the JSON without additional explanations."""
        # Safely handle string replacements
        safe_min_cvss = str(MIN_CVSS_SCORE)
        safe_products = ", ".join(PRODUCTS) if PRODUCTS else "No products specified"
        
        LIST_PROMPT = LIST_PROMPT.replace("min-cvss-score_to_check_in_prompt", safe_min_cvss)
        LIST_PROMPT = LIST_PROMPT.replace("products_to_check_in_prompt", safe_products)
        LIST_PROMPT = LIST_PROMPT.replace("from_time_to_check_in_prompt", FROM_THE_FOLLOWING_TIME)
        
        logger.info("Prompt:\n" + LIST_PROMPT)
        
        # Initialize the client with a valid API key
        if API_KEY:
            client = openai.OpenAI(api_key=API_KEY)
            # Fetch list of available models
            models = client.models.list()

            # Print all available model names
            for model in models:
                logger.info(model.id)
        else:
            logger.error("Cannot initialize OpenAI client: API key is missing")
            
    except Exception as e:
        logger.error(f"Error in setup_global_variables: {str(e)}")
        # Set some defaults to prevent crashes
        if not API_KEY:
            logger.critical("No API key available - functionality will be limited")
        if not client:
            logger.critical("OpenAI client not initialized")


def query_gpt(prompt, system_prompt, logger):
    """Send prompt to GPT and retrieve the CVEs with logging."""
    
    if not client:
        logger.error("OpenAI client not initialized. Cannot query GPT.")
        return None
        
    try:
        logger.info("Sending query to GPT model...")
            
        # Add explicit instructions for JSON format
        response = ""
        if(system_prompt != ""):
            response = client.chat.completions.create(
                model=MODEL,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": prompt}
                ],
                max_tokens=MAX_TOKENS
            )
        else:
            response = client.chat.completions.create(
                model=MODEL,
                messages=[
                    {"role": "user", "content": prompt}
                ],
                max_tokens=MAX_TOKENS
            )


        # Ensure the response is valid
        if not response or not response.choices:
            logger.error("GPT response is empty or malformed.")
            return None

        # Extract response text safely
        response_text = response.choices[0].message.content.strip() if response.choices and hasattr(response.choices[0], 'message') else ""
        
        if not response_text:
            logger.error("Empty response text from GPT")
            return None

        # Log the full GPT response
        logger.info(f"FULL GPT Response:\n{response_text}")
        return response_text

    except openai.APIConnectionError:
        logger.error("Failed to connect to OpenAI API. Check internet connection.")
        return None

    except openai.OpenAIError as e:
        logger.error(f"OpenAI API error: {str(e)}")
        return None

    except Exception as e:
        logger.error(f"Unexpected error in query_gpt: {str(e)}")
        return None


if __name__ == "__main__":
    try:
        
        logger = additionals.logger.setup_logger("alerts_vuln_cve_managment_helper.log")
        if(os.path.exists(JSON_OUTPUT_PATH)):
            os.remove(JSON_OUTPUT_PATH)
        try:
            env_dict = additionals.funcs.read_env_file(logger)
        except Exception as e:
            logger.error(f"Error reading environment file: {str(e)}")
            env_dict = {}
            
        try:
            connection = additionals.mysql_functions.setup_mysql_connection(env_dict, logger)
            query_result = additionals.mysql_functions.execute_query(connection, "SELECT config FROM configjson LIMIT 1", logger)
            
            if query_result and query_result[0] and query_result[0][0]:
                config_data = json.loads(query_result[0][0])
            else:
                logger.error("No configuration data retrieved from database")
                config_data = {}
        except Exception as e:
            logger.error(f"Error connecting to database or retrieving config: {str(e)}")
            config_data = {}
            
        setup_global_variables(config_data, logger)
        # Check for command line argument to set output path
        if len(sys.argv) > 1:
            JSON_OUTPUT_PATH = sys.argv[1]
            logger.info(f"Output path set from command line: {JSON_OUTPUT_PATH}")
        
        # Save the existing content if the file exists
        existing_data = []
        if os.path.exists(JSON_OUTPUT_PATH) and os.path.getsize(JSON_OUTPUT_PATH) > 0:
            try:
                with open(JSON_OUTPUT_PATH, 'r') as file:
                    existing_data = json.load(file)
                    if isinstance(existing_data, list):
                        logger.info(f"Loaded {len(existing_data)} existing CVEs from {JSON_OUTPUT_PATH}")
            except Exception as e:
                logger.error(f"Error reading existing JSON file: {str(e)}")
        
        cve_count = 0
        max_attempts = 10  # Limit the number of attempts to prevent infinite loops
        cve_list = ""
        """
        save_result = save_json_to_file(all_cves_json, logger)
        if save_result:
            logger.info(f"All CVE data successfully saved to {JSON_OUTPUT_PATH}")
        else:
            logger.error(f"Failed to save all CVE data to {JSON_OUTPUT_PATH}")
        elasticIp=config_data['ClientData']['API']['Elastic']["Ip"]
        
        additionals.elastic_api.enter_data(JSON_OUTPUT_PATH, "agentic_ai_vulnerability_management",elasticIp, logger)
        """
    except Exception as e:
        # Get global logger if it exists, otherwise create a basic one
        try:
            if 'logger' not in locals() or logger is None:
                import logging
                logging.basicConfig(level=logging.ERROR)
                logger = logging.getLogger("emergency_logger")
        except:
            pass
            
        try:
            logger.critical(f"Critical error in main execution: {str(e)}")
            logger.critical(traceback.format_exc())
        except:
            print(f"CRITICAL ERROR: {str(e)}")