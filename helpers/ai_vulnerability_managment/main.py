import os
import sys
import json
import traceback

# Get the absolute path of this script
script_path = os.path.abspath(__file__)
script_dir = os.path.dirname(script_path)
main_dir = os.path.abspath(os.path.join(script_dir, "../.."))
os.chdir(main_dir)
sys.path.insert(0, main_dir)
print(f"Current Working Directory: {os.getcwd()}")


import openai
import additionals.elastic_api
import helpers.ai_vulnerability_managment.apis.nvd_api_functions
import helpers.ai_vulnerability_managment.helpers.prompts_generator
import helpers.ai_vulnerability_managment.helpers.alerts
import helpers.ai_vulnerability_managment.helpers.auto_products_detection
from datetime import datetime, timedelta
import helpers.ai_vulnerability_managment.helpers.seperate_rules
import helpers.ai_vulnerability_managment.helpers.global_variables
import helpers.ai_vulnerability_managment.minimodules.run_yara
import helpers.ai_vulnerability_managment.minimodules.run_sigma
import helpers.ai_vulnerability_managment.minimodules.run_nuclei
import helpers.ai_vulnerability_managment.helpers.logger_helper
import helpers.ai_vulnerability_managment.helpers.run_modules

general_settings = {
    "VENDOR_NAME:": "ChatGPT",
    "LLM_API_KEY": "",  # Replace with your actual API key
    "NVD_API_KEY": "",
    "MODEL_NAME": "gpt-4o-search-preview",
    "PRODUCTS": [],
    "MAX_TOKENS": 4096,  # Ensure model can accept a lot of tokens
    "MIN_CVSS_SCORE": 8,
    "TEMPERATURE": 0.7,
    "PROMPT": "",
    "FromTheFollowingTime": "1",
    "SYSTEM_PROMPT": """prompt""",
    "JSON_OUTPUT_PATH": os.path.join("response_folder", "CVE_AI_MANAGMENT_RESULTS.json")
    
}



if __name__ == "__main__":
    try:
        logger = helpers.ai_vulnerability_managment.helpers.logger_helper.setup_logger("alerts_vuln_cve_managment_helper.log", log_to_stdout=True)
        files = ["sigma_rules.json", "nuclei_rules.json", "yara_rules.json", "mitigations.json", "known_exploits.json"]

        for file in files:
            path = f"response_folder/{file}"
            try: os.remove(path) 
            except FileNotFoundError: pass
        try: os.remove("logs/cve_managment_prompt.log") 
        except FileNotFoundError: pass
        prompt_logger = helpers.ai_vulnerability_managment.helpers.logger_helper.setup_logger("cve_managment_prompt.log", log_to_stdout=False, clean_format=True)
        env_dict = additionals.funcs.read_env_file(logger)
        previous_config_date = datetime.now().strftime('%d-%m-%Y-%H-%M-%S')
        if(os.path.exists(general_settings["JSON_OUTPUT_PATH"])):
            os.remove(general_settings["JSON_OUTPUT_PATH"])

        config_data = helpers.ai_vulnerability_managment.helpers.global_variables.get_config(logger)
        general_settings = helpers.ai_vulnerability_managment.helpers.global_variables.setup_global_variables(general_settings, config_data, logger)
        
        products_list = []

        if(general_settings["AutoProductsDetection"] == "true"):
            # Wrap this specific call in a try-except to isolate error if it happens here
            try:
                products_list = helpers.ai_vulnerability_managment.helpers.auto_products_detection.get_products_auto(general_settings, logger)
            except Exception as e:
                logger.error(f"Error in auto product detection: {str(e)}")
                logger.error(f"Traceback: {traceback.format_exc()}")
                # Continue execution with empty product list
                products_list = []
                
        products_list = products_list + general_settings["PRODUCTS"]
        llm_api_client = helpers.ai_vulnerability_managment.helpers.prompts_generator.get_llm_api(general_settings, logger)
        products_cpe_dict = helpers.ai_vulnerability_managment.helpers.prompts_generator.products_list_to_cpe_dict(llm_api_client, general_settings, products_list, logger, prompt_logger)
        logger.info("cpe_dict:" + str(products_cpe_dict))
        json_before_ai = helpers.ai_vulnerability_managment.apis.nvd_api_functions.nvd_func_calls(general_settings, products_cpe_dict, logger)

        final_json = helpers.ai_vulnerability_managment.helpers.prompts_generator.enrich_cve_data(llm_api_client, json_before_ai, general_settings, logger, prompt_logger)
        #final_json = {k: v for k, v in final_json["vulnerabilities"].items()}
        logger.info("final json:" + str(final_json))
        if final_json:
            with open(general_settings["JSON_OUTPUT_PATH"], 'w', encoding='utf-8') as f:
                json.dump(final_json, f, indent=2, ensure_ascii=False)
            sigma_rules, nuclei_rules, yara_rules, mitigations_data, known_exploits_data = helpers.ai_vulnerability_managment.helpers.seperate_rules.extract_rules(final_json, logger)
            elasticIp=config_data['ClientData']['API']['Elastic']["Ip"]
            additionals.elastic_api.enter_data(general_settings["JSON_OUTPUT_PATH"], "agentic_ai_vulnerability_management",elasticIp, logger)
            helpers.ai_vulnerability_managment.helpers.alerts.add_new_alerts(final_json, logger)

            config_data = helpers.ai_vulnerability_managment.helpers.run_modules.run_concurrent_scans(general_settings, config_data, yara_rules, sigma_rules, logger)
            additionals.funcs.connect_db_update_config(env_dict, previous_config_date, config_data, logger)
        else:
            logger.error(f"There is nothing in final_json")
        
    except Exception as e:
        # Log the full traceback for detailed error information
        error_traceback = traceback.format_exc()
        logger.error(f"General error: {str(e)}")
        logger.error(f"Error traceback: {error_traceback}")
        
        # You can also print to console for immediate feedback
        print(f"ERROR: {str(e)}")
        print(f"TRACEBACK: {error_traceback}")