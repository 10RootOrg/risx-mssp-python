#!/usr/bin/env python3
import os
import sys
import json
import traceback

# Get the absolute path of this script
script_path = os.path.abspath(__file__)
script_dir = os.path.dirname(script_path)
main_dir = os.path.abspath(os.path.join(script_dir, "../.."))
os.chdir(main_dir)
sys.path.insert(0, main_dir)
print(f"Current Working Directory: {os.getcwd()}")

import additionals.mysql_functions
import openai
import additionals.logger
import additionals.funcs
import additionals.elastic_api

# Configuration Variables
API_KEY = ""  # Replace with your actual API key
MODEL = "gpt-4o-search-preview"
PRODUCTS = []
MAX_TOKENS = 4096  # Ensure model can accept a lot of tokens
MIN_CVSS_SCORE = 8
FROM_THE_FOLLOWING_TIME = "2 days"
PROMPT = """Retrieve CVEs from the past from_time_to_check_in_prompt with a CVSS score above min-cvss-score_to_check_in_prompt that are relevant to the following devices:
Products: products_to_check_in_prompt
Return the data in JSON format with a maximum of 2 CVEs per response. If there are more than 2 CVEs available, prepend true before the JSON; otherwise, prepend false. add it as the boolean and then the json with the "!!!!!" operator between them and the object. without any thing else in between 

Each CVE entry should have the following fields:

CVE ID – The identifier of the CVE
CVSS Score – The severity rating
Affected Device – The impacted system
YARA Rule – A YARA rule for detecting the vulnerability
Sigma Rule – A Sigma rule for detecting the vulnerability
Mitigation Tips – Recommended actions to mitigate the vulnerability
Generate YARA and Sigma rules specific to each CVE as seralize json object. Return only the JSON without additional explanations."""

CONTINUE_PROMPT = """Continue retrieving additional CVEs from the same criteria, starting after the last CVE previously provided, and again limit your response to a maximum of 2 CVEs per JSON response. Maintain the same response format: if more CVEs are available after this set, prepend true before the JSON; otherwise, prepend false add it as the boolean and then the json with the "!!!!!" operator between them and the object. without any thing else in between Include all fields exactly as previously defined, including generated YARA and Sigma rules. Return only the JSON without additional explanations."""
JSON_OUTPUT_PATH = os.path.join("response_folder", "CVE_AI_MANAGMENT_RESULTS.json") # Default path, can be overridden

current_cve_index = 0
all_cves = []
client = None

def setup_global_variables(config, logger):
    global API_KEY, MODEL, MAX_TOKENS, PROMPT, PRODUCTS, JSON_OUTPUT_PATH, client, MIN_CVSS_SCORE, FROM_THE_FOLLOWING_TIME
    try:
        API_KEY = config.get('ClientData', {}).get('API', {}).get('AiManagement', '')
        if not API_KEY:
            logger.warning("API key not found in configuration")
            
        ai_config = config.get("General", {}).get("IntervalConfigurations", {}).get("AiManagement", {})
        if not ai_config:
            logger.warning("AiManagement configuration not found")
            ai_config = {}
            
        if ai_config.get("MODEL"):
            MODEL = ai_config["MODEL"]
        if ai_config.get("MAX_TOKENS"):
            MAX_TOKENS = ai_config["MAX_TOKENS"]
        if ai_config.get("MIN_CVSS_SCORE"):
            MIN_CVSS_SCORE = ai_config["MIN_CVSS_SCORE"]
        if ai_config.get("PROMPT"):
            PROMPT = ai_config["PROMPT"]
        if ai_config.get("PRODUCTS"):
            PRODUCTS = ai_config["PRODUCTS"]
        if ai_config.get("FromTheFollowingTime"):
            FROM_THE_FOLLOWING_TIME = ai_config["FromTheFollowingTime"]
        # Safely handle string replacements
        safe_min_cvss = str(MIN_CVSS_SCORE)
        safe_products = ", ".join(PRODUCTS) if PRODUCTS else "No products specified"
        
        PROMPT = PROMPT.replace("min-cvss-score_to_check_in_prompt", safe_min_cvss)
        PROMPT = PROMPT.replace("products_to_check_in_prompt", safe_products)
        PROMPT = PROMPT.replace("from_time_to_check_in_prompt", FROM_THE_FOLLOWING_TIME)
        
        logger.info("Prompt:\n" + PROMPT)
        
        # Initialize the client with a valid API key
        if API_KEY:
            client = openai.OpenAI(api_key=API_KEY)
            # Fetch list of available models
            models = client.models.list()

            # Print all available model names
            for model in models:
                logger.info(model.id)
        else:
            logger.error("Cannot initialize OpenAI client: API key is missing")
            
    except Exception as e:
        logger.error(f"Error in setup_global_variables: {str(e)}")
        # Set some defaults to prevent crashes
        if not API_KEY:
            logger.critical("No API key available - functionality will be limited")
        if not client:
            logger.critical("OpenAI client not initialized")


def query_gpt(first_flag, logger):
    """Send prompt to GPT and retrieve the CVEs with logging."""
    
    if not client:
        logger.error("OpenAI client not initialized. Cannot query GPT.")
        return None
        
    try:
        logger.info("Sending query to GPT model...")
        temp_prompt = PROMPT
        if not (first_flag):
            temp_prompt = CONTINUE_PROMPT
            
        # Add explicit instructions for JSON format
        system_prompt = """You are an expert in cybersecurity providing CVE details. Return complete, well-formed JSON without truncation.
For format consistency, always return your data as an array of objects, even if there is only one object.
Each object should follow this structure exactly:
{
  "CVE ID": "CVE-YYYY-NNNNN",
  "CVSS Score": 9.8,
  "Affected Device": "Product Name",
  "YARA Rule": { ... },
  "Sigma Rule": { ... },
  "Mitigation Tips": [ ... ]
}
Use the standard field names exactly as shown above."""
            
        response = client.chat.completions.create(
            model=MODEL,
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": temp_prompt}
            ],
            max_tokens=MAX_TOKENS
        )

        # Ensure the response is valid
        if not response or not response.choices:
            logger.error("GPT response is empty or malformed.")
            return None

        # Extract response text safely
        response_text = response.choices[0].message.content.strip() if response.choices and hasattr(response.choices[0], 'message') else ""
        
        if not response_text:
            logger.error("Empty response text from GPT")
            return None

        # Log the full GPT response
        logger.info(f"FULL GPT Response:\n{response_text}")

        # Check for incomplete JSON responses
        if response_text.count("[") != response_text.count("]") or response_text.count("{") != response_text.count("}"):
            logger.warning("Detected incomplete JSON in response (unbalanced brackets)")
            # Try to repair the JSON by finding the last complete CVE entry
            if "true!!!!!" in response_text and "[" in response_text and "]" not in response_text:
                # Add closing brackets if needed
                response_text += "\n]"
                logger.info("Added missing closing bracket to incomplete JSON array")
            elif "true!!!!!" in response_text and "[" not in response_text and "{" in response_text:
                # Might be a single object instead of an array
                response_text = response_text.replace("true!!!!!", "true!!!!![") + "]"
                logger.info("Wrapped single object in array brackets")
            
        return response_text

    except openai.APIConnectionError:
        logger.error("Failed to connect to OpenAI API. Check internet connection.")
        return None

    except openai.OpenAIError as e:
        logger.error(f"OpenAI API error: {str(e)}")
        return None

    except Exception as e:
        logger.error(f"Unexpected error in query_gpt: {str(e)}")
        return None


def parse_response(response_text, logger):
    """Parse the response and extract CVEs."""
    global all_cves
    
    if not response_text:
        logger.error("Empty response text received in parse_response")
        return False
        
    try:
        response_text = response_text.strip()
        
        # Handle truncated responses - check for balanced brackets
        if response_text.count("[") != response_text.count("]") or response_text.count("{") != response_text.count("}"):
            logger.warning("Detected unbalanced brackets in the response - attempting to fix")
            # Try to fix by adding missing closing brackets
            if "[" in response_text and "]" not in response_text:
                response_text += "]"
            if "{" in response_text and "}" not in response_text:
                response_text += "}"
            logger.info("Added missing brackets to fix unbalanced JSON")
            
        # Check if the response has the expected format with the "!!!!!" separator
        if "!!!!!" in response_text:
            parts = response_text.split("!!!!!")
            if len(parts) != 2:
                logger.warning(f"Unexpected format: split by '!!!!!' resulted in {len(parts)} parts instead of 2")
                # Try to recover by looking for JSON
                json_start = response_text.find("[")
                if json_start != -1:
                    json_data = response_text[json_start:]
                    prepend_true = "true" in response_text[:json_start].lower()
                elif response_text.find("{") != -1:
                    # It might be a single CVE object instead of an array
                    json_start = response_text.find("{")
                    json_data = response_text[json_start:]
                    prepend_true = "true" in response_text[:json_start].lower()
                    # Wrap in array brackets if it's a single object
                    if not json_data.startswith("["):
                        json_data = "[" + json_data + "]"
                        logger.info("Wrapped single CVE object in array brackets")
                else:
                    logger.error("Cannot find JSON object or array in response")
                    return False
            else:
                prepend_text = parts[0].strip().lower()
                json_data = parts[1].strip()
                prepend_true = prepend_text == "true"
                
                # Check if it's a single object (not wrapped in array)
                if json_data.startswith("{") and not json_data.startswith("[{"):
                    json_data = "[" + json_data + "]"
                    logger.info("Wrapped single CVE object in array brackets")
        else:
            # Try to find JSON array or object directly
            json_start = response_text.find("[")
            if json_start != -1:
                json_data = response_text[json_start:]
                prepend_true = "true" in response_text[:json_start].lower()
            elif response_text.find("{") != -1:
                # It might be a single CVE object
                json_start = response_text.find("{")
                json_data = "[" + response_text[json_start:] + "]"
                prepend_true = "true" in response_text[:json_start].lower()
                logger.info("Wrapped single CVE object in array brackets")
            else:
                logger.error("Cannot find JSON object or array in response")
                return False
        
        # Clean up JSON data - sometimes it's wrapped in ```json ... ``` code blocks
        if json_data.startswith("```"):
            json_start = json_data.find("[")
            if json_start != -1:
                json_end = json_data.rfind("]") + 1
                if json_end <= 0:  # If no closing bracket found, try to find the last complete object
                    last_brace = json_data.rfind("}")
                    if last_brace > 0:
                        # Check if this brace is the end of an object in the array
                        json_data = json_data[json_start:last_brace+1] + "]"
                        logger.info("Repaired truncated JSON by adding closing bracket")
                    else:
                        logger.error("Cannot find valid JSON structure in code block")
                        return False
                else:
                    json_data = json_data[json_start:json_end]
            elif json_data.find("{") != -1:
                # It might be a single CVE object
                json_start = json_data.find("{")
                json_end = json_data.rfind("}") + 1
                if json_end > 0:
                    json_data = "[" + json_data[json_start:json_end] + "]"
                    logger.info("Wrapped single CVE object from code block in array brackets")
                else:
                    logger.error("Cannot find valid JSON structure in code block")
                    return False
            else:
                logger.error("Cannot find JSON object or array in code block")
                return False
        
        # Try to repair truncated JSON responses
        if json_data.count("[") > json_data.count("]"):
            json_data += "]" * (json_data.count("[") - json_data.count("]"))
            logger.info(f"Added {json_data.count('[') - json_data.count(']')} missing closing brackets to JSON array")
        
        if json_data.count("{") > json_data.count("}"):
            json_data += "}" * (json_data.count("{") - json_data.count("}"))
            logger.info(f"Added {json_data.count('{') - json_data.count('}')} missing closing braces to JSON objects")
        
        # Try to validate JSON before parsing
        try:
            if len(json_data) == 0:
                logger.info("There is no data!")
                return False
            cve_list = json.loads(json_data)
            
            # If it's not a list, convert to a list with one item
            if not isinstance(cve_list, list):
                logger.info("Converting single CVE object to list")
                cve_list = [cve_list]
            
        except json.JSONDecodeError as e:
            # Try to clean the JSON data if possible
            logger.warning(f"Initial JSON validation failed: {str(e)}")
            
            # Look for JSON array brackets or object braces
            if '[' in json_data and ']' in json_data:
                start_idx = json_data.find('[')
                end_idx = json_data.rfind(']') + 1
                if start_idx >= 0 and end_idx > start_idx:
                    logger.info("Attempting to extract JSON array from response")
                    json_data = json_data[start_idx:end_idx]
            elif '{' in json_data and '}' in json_data:
                start_idx = json_data.find('{')
                end_idx = json_data.rfind('}') + 1
                if start_idx >= 0 and end_idx > start_idx:
                    logger.info("Attempting to extract single JSON object from response")
                    json_data = "[" + json_data[start_idx:end_idx] + "]"
            
            # If we still have an incomplete JSON, try to repair it by extracting complete objects
            if json_data.count("[") > json_data.count("]") or json_data.count("{") > json_data.count("}"):
                # Try to extract the last complete CVE object
                logger.warning("JSON still incomplete after extraction, attempting to fix individual objects")
                try:
                    # Find all complete CVE objects by looking for "{...}" patterns
                    import re
                    pattern = r'(\{[^{}]*(?:\{[^{}]*\}[^{}]*)*\})'
                    complete_objects = re.findall(pattern, json_data)
                    if complete_objects:
                        # Create a new JSON array with the complete objects
                        json_data = "[" + ",".join(complete_objects) + "]"
                        logger.info(f"Extracted {len(complete_objects)} complete CVE objects")
                except Exception as e:
                    logger.error(f"Error trying to extract complete objects: {str(e)}")
            
            try:
                cve_list = json.loads(json_data)
                # If it's not a list, convert to a list with one item
                if not isinstance(cve_list, list):
                    logger.info("Converting single CVE object to list after cleanup")
                    cve_list = [cve_list]
            except json.JSONDecodeError as e:
                logger.error(f"Failed to parse JSON response after cleanup: {str(e)}")
                logger.debug(f"Problematic JSON data: {json_data}")
                return False
        
        # Validate that we have a list
        if not isinstance(cve_list, list):
            logger.error("JSON data is not a list")
            return False
        
        # Process CVEs with field name standardization
        valid_cves = []
        for cve in cve_list:
            if not isinstance(cve, dict):
                logger.warning(f"Skipping non-dictionary CVE entry: {cve}")
                continue
                
            # Log the original CVE for debugging
            logger.debug(f"Processing CVE entry: {json.dumps(cve, indent=2)}")
            
            # Standardize field names (handle both naming conventions)
            standardized_cve = {}
            field_mappings = {
                "CVE ID": ["CVE ID", "CVE_ID", "cve_id", "cve id", "CVE-ID", "cve-id"],
                "CVSS Score": ["CVSS Score", "CVSS_Score", "cvss_score", "cvss score", "CVSS-Score", "cvss-score", 
                               "cvss_v3_score", "CVSS_V3_Score", "CVSS V3 Score", "CVSS v3 Score", "cvss v3 score"],
                "Affected Device": ["Affected Device", "Affected_Device", "affected_device", "affected device", "Affected-Device", "affected-device"]
            }
            
            # Attempt to standardize all required fields
            for standard_field, possible_fields in field_mappings.items():
                for field in possible_fields:
                    if field in cve:
                        standardized_cve[standard_field] = cve[field]
                        break
            
            # If Affected Device is missing but we have Affected_Products, use the first one
            if "Affected Device" not in standardized_cve:
                # Check all variations of affected_products field
                for product_field in ["Affected_Products", "affected_products", "AffectedProducts", "affectedProducts"]:
                    if product_field in cve and cve[product_field]:
                        if isinstance(cve[product_field], list):
                            if isinstance(cve[product_field][0], dict):
                                # Check for various product name fields in the dict
                                for name_field in ["product_name", "product", "name", "Product", "product_name"]:
                                    if name_field in cve[product_field][0]:
                                        standardized_cve["Affected Device"] = cve[product_field][0][name_field]
                                        break
                                # If we still don't have a product name, use the vendor + product if available
                                if "Affected Device" not in standardized_cve and "vendor" in cve[product_field][0] and "product" in cve[product_field][0]:
                                    standardized_cve["Affected Device"] = f"{cve[product_field][0]['vendor']} {cve[product_field][0]['product']}"
                            else:
                                standardized_cve["Affected Device"] = cve[product_field][0]
                        else:
                            standardized_cve["Affected Device"] = cve[product_field]
                        break  # Break once we've found a valid product field
            
            # Handle special fields for YARA and Sigma rules
            special_fields_mapping = {
                "YARA Rule": ["YARA Rule", "YARA_Rule", "yara_rule", "Yara Rule", "yara rule", "YARA rule"],
                "Sigma Rule": ["Sigma Rule", "Sigma_Rule", "sigma_rule", "sigma rule", "SIGMA rule", "SIGMA Rule"],
                "Mitigation Tips": ["Mitigation Tips", "Mitigation_Tips", "mitigation_tips", "mitigation tips", "mitigations", "Mitigations"]
            }
            
            for standard_field, possible_fields in special_fields_mapping.items():
                for field in possible_fields:
                    if field in cve:
                        standardized_cve[standard_field] = cve[field]
                        break
            
            # Copy all other fields
            for key, value in cve.items():
                # Skip the ones we've already handled
                skip = False
                for possible_fields in field_mappings.values():
                    if key in possible_fields:
                        skip = True
                        break
                for possible_fields in special_fields_mapping.values():
                    if key in possible_fields:
                        skip = True
                        break
                
                if not skip:
                    standardized_cve[key] = value
            
            # Check if all required fields are present after standardization
            required_fields = ["CVE ID", "CVSS Score", "Affected Device"]
            missing_fields = [field for field in required_fields if field not in standardized_cve]
            
            if missing_fields:
                # If CVE ID and CVSS Score are present but Affected Device is missing, try to auto-create it
                if len(missing_fields) == 1 and missing_fields[0] == "Affected Device":
                    # First try from the description
                    if "description" in cve or "Description" in cve:
                        # Get description regardless of case
                        desc = cve.get("description", cve.get("Description", ""))
                        # Look for common product terms in the description
                        product_indicators = ["Windows", "Linux", "Ubuntu", "CrowdStrike", "Server", "Falcon", 
                                             "Cisco", "Microsoft", "Google Chrome", "Mozilla", "Firefox", "Apple", 
                                             "macOS", "Android", "iOS", "VMware", "AWS", "Azure", "IBM", "Oracle"]
                        for product in product_indicators:
                            if product in desc:
                                standardized_cve["Affected Device"] = product
                                missing_fields = []
                                logger.info(f"Auto-created Affected Device field from description: {product}")
                                break
                                
                    # If still missing and we have cvss_v3_score but no CVSS Score, copy it over
                    if "CVSS Score" in missing_fields and "cvss_v3_score" in cve:
                        standardized_cve["CVSS Score"] = cve["cvss_v3_score"]
                        missing_fields.remove("CVSS Score")
                        logger.info(f"Copied cvss_v3_score to CVSS Score: {cve['cvss_v3_score']}")
                
                if missing_fields:
                    logger.warning(f"CVE entry missing required fields {missing_fields} after standardization: {cve}")
                    continue
            
            valid_cves.append(standardized_cve)
        
        if not valid_cves:
            logger.error("No valid CVE entries found in response")
            return False
        
        all_cves.extend(valid_cves)
        return prepend_true
            
    except Exception as e:
        logger.error(f"Unexpected error in parse_response: {str(e)}")
        logger.error(traceback.format_exc())
        return False


def get_next_cves(first_flag, logger):
    """Retrieve the next batch of CVEs."""
    global current_cve_index, all_cves
    
    try:
        # Check if we have CVEs in our existing cache
        if current_cve_index < len(all_cves):
            next_cves = all_cves[current_cve_index:current_cve_index + 2]  # Changed to match 2 CVEs per response in prompt
            current_cve_index += len(next_cves)
            prepend_true = current_cve_index < len(all_cves)
            return prepend_true, json.dumps(next_cves, indent=4)
        
        # If we're here, we need to fetch more CVEs
        response_text = query_gpt(first_flag, logger)
        if not response_text:
            logger.error("Failed to get response from GPT")
            return False, json.dumps([])
        
        # Parse the new response
        more_available = parse_response(response_text, logger)
        
        # Get the newly added CVEs
        new_cves_added = current_cve_index < len(all_cves)
        if new_cves_added:
            next_cves = all_cves[current_cve_index:current_cve_index + 2]  # Changed to match 2 CVEs per response in prompt
            current_cve_index += len(next_cves)
            logger.info(f"More CVEs available: {more_available}")
            return more_available, json.dumps(next_cves, indent=4)
        else:
            # No new CVEs were added - check if we should retry with a simplified prompt
            if first_flag == False and len(all_cves) > 0:
                # Already tried with CONTINUE_PROMPT, no need to retry
                logger.info("No more CVEs available")
                return False, json.dumps([])
            
            # First attempt failed but we haven't tried a simplified approach yet
            if first_flag and not new_cves_added:
                logger.warning("First attempt failed to add CVEs, trying with simplified prompt")
                # Simplified prompt that focuses on just returning valid JSON
                global CONTINUE_PROMPT
                backup_continue_prompt = CONTINUE_PROMPT
                CONTINUE_PROMPT = """
                Return 2 CVEs that have a CVSS score above 8 and are relevant to Windows or Linux systems.
                Include only the CVE ID, CVSS Score, Affected Device, YARA Rule, Sigma Rule, and Mitigation Tips.
                Format as a simple JSON array of 2 objects. If more CVEs are available after these, prepend 'true!!!!!' before the JSON, otherwise prepend 'false!!!!!'.
                Return only the JSON without additional explanations.
                """
                try:
                    response_text = query_gpt(False, logger)  # Use the simplified prompt
                    if response_text:
                        more_available = parse_response(response_text, logger)
                        new_cves_added = current_cve_index < len(all_cves)
                        if new_cves_added:
                            next_cves = all_cves[current_cve_index:current_cve_index + 2]
                            current_cve_index += len(next_cves)
                            logger.info(f"Successfully retrieved CVEs with simplified prompt")
                            return more_available, json.dumps(next_cves, indent=4)
                except Exception as e:
                    logger.error(f"Error with simplified prompt: {str(e)}")
                finally:
                    # Restore the original continue prompt
                    CONTINUE_PROMPT = backup_continue_prompt
            
            # No new CVEs were added
            logger.info("No more CVEs available")
            return False, json.dumps([])
    except Exception as e:
        logger.error(f"Unexpected error in get_next_cves: {str(e)}")
        logger.error(traceback.format_exc())
        return False, json.dumps([])


def save_json_to_file(cve_data, logger):
    """Save the CVE data to a JSON file, combining with existing data if the file exists."""
    try:
        # Ensure we have valid JSON data
        if not cve_data:
            logger.error("Empty CVE data received, nothing to save")
            return False
            
        # Parse the current JSON data
        try:
            new_cves = json.loads(cve_data)
            
            # Validate that new_cves is a list
            if not isinstance(new_cves, list):
                logger.error(f"CVE data is not a list: {type(new_cves)}")
                return False
                
            # If new_cves is empty, no need to save
            if not new_cves:
                logger.info("No new CVEs to save")
                return True
                
        except json.JSONDecodeError as e:
            logger.error(f"Failed to parse CVE JSON data: {str(e)}")
            return False
        
        # Ensure output directory exists
        output_dir = os.path.dirname(JSON_OUTPUT_PATH)
        if output_dir and not os.path.exists(output_dir):
            logger.info(f"Creating output directory: {output_dir}")
            os.makedirs(output_dir, exist_ok=True)
        
        # Check if file exists and has content
        combined_data = []
        if os.path.exists(JSON_OUTPUT_PATH) and os.path.getsize(JSON_OUTPUT_PATH) > 0:
            logger.info(f"JSON file exists at {JSON_OUTPUT_PATH}, combining with existing data...")
            try:
                with open(JSON_OUTPUT_PATH, 'r') as file:
                    existing_data = json.load(file)
                    
                # Ensure existing_data is a list
                if not isinstance(existing_data, list):
                    logger.warning(f"Existing data is not a list: {type(existing_data)}")
                    existing_data = []
                    
                # Combine new data with existing data
                # Create a set of CVE IDs that are already in the existing data
                existing_cve_ids = set()
                for cve in existing_data:
                    for id_field in ["CVE ID", "CVE_ID"]:
                        if id_field in cve:
                            existing_cve_ids.add(cve[id_field])
                            break
                
                # Only add new CVEs that aren't already in the existing data
                for cve in new_cves:
                    cve_id = None
                    for id_field in ["CVE ID", "CVE_ID"]:
                        if id_field in cve:
                            cve_id = cve[id_field]
                            break
                    
                    if cve_id and cve_id not in existing_cve_ids:
                        existing_data.append(cve)
                        existing_cve_ids.add(cve_id)
                
                combined_data = existing_data
            except json.JSONDecodeError as e:
                logger.error(f"Error parsing existing JSON file: {str(e)}")
                # Continue with just the new data
                combined_data = new_cves
            except Exception as e:
                logger.error(f"Error reading existing JSON file: {str(e)}")
                # Continue with just the new data
                combined_data = new_cves
        else:
            logger.info(f"Creating new JSON file at {JSON_OUTPUT_PATH}")
            combined_data = new_cves
        
        # Write the combined data back to the file
        try:
            with open(JSON_OUTPUT_PATH, 'w') as file:
                json.dump(combined_data, file, indent=4)
                
            logger.info(f"Successfully saved data to {JSON_OUTPUT_PATH}")
            return True
        except Exception as e:
            logger.error(f"Error writing to JSON file: {str(e)}")
            return False
            
    except Exception as e:
        logger.error(f"Error saving JSON data: {str(e)}")
        return False


if __name__ == "__main__":
    try:
        logger = additionals.logger.setup_logger("alerts_vuln_cve_managment_helper.log")
        
        try:
            env_dict = additionals.funcs.read_env_file(logger)
        except Exception as e:
            logger.error(f"Error reading environment file: {str(e)}")
            env_dict = {}
            
        try:
            connection = additionals.mysql_functions.setup_mysql_connection(env_dict, logger)
            query_result = additionals.mysql_functions.execute_query(connection, "SELECT config FROM configjson LIMIT 1", logger)
            
            if query_result and query_result[0] and query_result[0][0]:
                config_data = json.loads(query_result[0][0])
            else:
                logger.error("No configuration data retrieved from database")
                config_data = {}
        except Exception as e:
            logger.error(f"Error connecting to database or retrieving config: {str(e)}")
            config_data = {}
            
        setup_global_variables(config_data, logger)
        
        # Check for command line argument to set output path
        if len(sys.argv) > 1:
            JSON_OUTPUT_PATH = sys.argv[1]
            logger.info(f"Output path set from command line: {JSON_OUTPUT_PATH}")
        
        # Save the existing content if the file exists
        existing_data = []
        if os.path.exists(JSON_OUTPUT_PATH) and os.path.getsize(JSON_OUTPUT_PATH) > 0:
            try:
                with open(JSON_OUTPUT_PATH, 'r') as file:
                    existing_data = json.load(file)
                    if isinstance(existing_data, list):
                        logger.info(f"Loaded {len(existing_data)} existing CVEs from {JSON_OUTPUT_PATH}")
            except Exception as e:
                logger.error(f"Error reading existing JSON file: {str(e)}")
        
        # Continue fetching CVEs
        prepend_true = True
        first_flag = True
        cve_count = 0
        max_attempts = 10  # Limit the number of attempts to prevent infinite loops
        
        for attempt in range(max_attempts):
            logger.info(f"Attempt {attempt+1}/{max_attempts}")
            prepend_true, cve_json = get_next_cves(first_flag, logger)
            first_flag = False
            
            # Parse the current JSON to count CVEs
            try:
                cve_batch = json.loads(cve_json)
                if isinstance(cve_batch, list):
                    cve_count += len(cve_batch)
                    logger.info(f"Retrieved {len(cve_batch)} CVEs in this batch")
                    
                    # Save progress after each successful batch
                    save_result = save_json_to_file(cve_json, logger)
                    if save_result:
                        logger.info(f"Batch of CVE data successfully saved to {JSON_OUTPUT_PATH}")
                    else:
                        logger.error(f"Failed to save batch of CVE data to {JSON_OUTPUT_PATH}")
            except json.JSONDecodeError as e:
                logger.error(f"Error parsing JSON in current batch: {str(e)}")
            
            if not prepend_true:
                logger.info("No more CVEs available, finished fetching")
                break
        
        logger.info(f"Fetched a total of {cve_count} CVEs")
        logger.info(f"Saving final CVE data to {JSON_OUTPUT_PATH}")
        
        # Save all CVEs at the end
        all_cves_json = json.dumps(all_cves, indent=4)
        save_result = save_json_to_file(all_cves_json, logger)
        if save_result:
            logger.info(f"All CVE data successfully saved to {JSON_OUTPUT_PATH}")
        else:
            logger.error(f"Failed to save all CVE data to {JSON_OUTPUT_PATH}")
        elasticIp=config_data['ClientData']['API']['Elastic']["Ip"]
        
        additionals.elastic_api.enter_data(JSON_OUTPUT_PATH, "agentic_ai_vulnerability_management",elasticIp, logger)
    except Exception as e:
        # Get global logger if it exists, otherwise create a basic one
        try:
            if 'logger' not in locals() or logger is None:
                import logging
                logging.basicConfig(level=logging.ERROR)
                logger = logging.getLogger("emergency_logger")
        except:
            pass
            
        try:
            logger.critical(f"Critical error in main execution: {str(e)}")
            logger.critical(traceback.format_exc())
        except:
            print(f"CRITICAL ERROR: {str(e)}")