import requests
import json
import time
import re
import os
from datetime import datetime, timedelta

def nvd_func_calls(general_settings, products_cpe_dict, logger):
    """
    Call the NVD API function and handle the dictionary result.
    
    Parameters:
        general_settings (dict): Application settings
        products_cpe_dict (dict): Dictionary of product names to CPE strings
        logger: Logger object
        
    Returns:
        dict: Dictionary of vulnerabilities, or empty dict if none found
    """
    # Example parameters
    max_vulnerabilities = 1000
    days_back = int(general_settings["FromTheFollowingTime"])
    start_date = (datetime.now() - timedelta(days=days_back)).strftime("%Y-%m-%d")
    
    # Get vulnerabilities - now returns a dictionary, not a DataFrame
    result = get_cves_from_nvd_multi_request(
        max_vulnerabilities=max_vulnerabilities,
        start_date=start_date,
        cpe_dict=products_cpe_dict,
        min_cvss_score=general_settings["MIN_CVSS_SCORE"],
        api_key=general_settings["NVD_API_KEY"],
        logger=logger
    )
    
    # Display summary
    if result and "vulnerabilities" in result and len(result["vulnerabilities"]) > 0:
        num_vulns = len(result["vulnerabilities"])
        logger.info(f"Found {num_vulns} vulnerabilities")
        
        # Export to JSON file
        try:
            output_json_file = os.path.join("response_folder", "nvd_vulnerabilities_before_AI.json")
            with open(output_json_file, 'w', encoding='utf-8') as f:
                json.dump(result, f, indent=2, ensure_ascii=False)
            logger.info(f"JSON results exported to {output_json_file}")
        except Exception as e:
            logger.error(f"Error exporting results: {str(e)}")
    else:
        logger.info("No vulnerabilities found matching the criteria")
        # Initialize an empty result if none was returned
        if not result:
            result = {"vulnerabilities": {}}
    
    # Always return the result, even if empty
    return result

def split_date_range(start_date_str, end_date_str, max_days=120):
    """
    Split a date range into chunks of max_days or less.
    
    Parameters:
        start_date_str (str): Start date in YYYY-MM-DD format
        end_date_str (str): End date in YYYY-MM-DD format
        max_days (int): Maximum number of days per chunk (default 120)
        
    Returns:
        list: List of tuples (start_date, end_date) for each chunk
    """
    start_date = datetime.strptime(start_date_str, "%Y-%m-%d")
    end_date = datetime.strptime(end_date_str, "%Y-%m-%d")
    
    date_ranges = []
    current_start = start_date
    
    while current_start < end_date:
        # Calculate the end of this chunk
        chunk_end = current_start + timedelta(days=max_days - 1)
        
        # Don't exceed the overall end date
        if chunk_end > end_date:
            chunk_end = end_date
        
        date_ranges.append((
            current_start.strftime("%Y-%m-%d"),
            chunk_end.strftime("%Y-%m-%d")
        ))
        
        # Move to the next chunk
        current_start = chunk_end + timedelta(days=1)
    
    return date_ranges

def get_cves_from_nvd_multi_request(max_vulnerabilities=100, start_date=None, cpe_dict=None, 
                                   min_cvss_score=None, api_key=None, logger=None):
    """
    Fetch CVEs from NVD API with automatic handling of 120-day limitation.
    Makes multiple requests if the date range exceeds 120 days.
    
    Parameters:
        max_vulnerabilities (int): Maximum number of vulnerabilities to fetch
        start_date (str): Starting date for vulnerability publication (YYYY-MM-DD)
        cpe_dict (dict): Dictionary mapping product names to CPE strings
        min_cvss_score (float): Minimum CVSS score to include
        api_key (str): NVD API key
        logger: Logger object
        
    Returns:
        dict: JSON object containing vulnerability data
    """
    # Set default dates if not provided
    end_date = datetime.now().strftime("%Y-%m-%d")
    if start_date is None:
        # Default to 30 days ago if not specified
        start_date = (datetime.now() - timedelta(days=30)).strftime("%Y-%m-%d")
    
    if logger:
        logger.info(f"Total date range: {start_date} to {end_date}")
    else:
        # Create a simple print-based logger if none provided
        class SimpleLogger:
            def info(self, msg): print(f"INFO: {msg}")
            def warning(self, msg): print(f"WARNING: {msg}")
            def error(self, msg): print(f"ERROR: {msg}")
        logger = SimpleLogger()
    
    # Calculate the total number of days
    start_dt = datetime.strptime(start_date, "%Y-%m-%d")
    end_dt = datetime.strptime(end_date, "%Y-%m-%d")
    total_days = (end_dt - start_dt).days + 1
    
    logger.info(f"Total days to fetch: {total_days}")
    
    # Split the date range into 120-day chunks if necessary
    date_ranges = split_date_range(start_date, end_date, max_days=120)
    logger.info(f"Split into {len(date_ranges)} requests due to 120-day API limitation")
    
    # Initialize combined results
    all_vulnerabilities = {}
    
    # Process each date range
    for i, (chunk_start, chunk_end) in enumerate(date_ranges, 1):
        logger.info(f"Processing chunk {i}/{len(date_ranges)}: {chunk_start} to {chunk_end}")
        
        # Get vulnerabilities for this chunk
        chunk_result = get_cves_from_nvd_single_request(
            max_vulnerabilities=max_vulnerabilities,
            start_date=chunk_start,
            end_date=chunk_end,
            cpe_dict=cpe_dict,
            min_cvss_score=min_cvss_score,
            api_key=api_key,
            logger=logger
        )
        
        # Merge results
        if chunk_result and "vulnerabilities" in chunk_result:
            chunk_vulnerabilities = chunk_result["vulnerabilities"]
            
            for cve_id, vuln_data in chunk_vulnerabilities.items():
                # Add to our results if it's new or has a higher CVSS score
                if cve_id in all_vulnerabilities:
                    existing_cvss = 0.0
                    existing_score = all_vulnerabilities[cve_id].get("cvss_v3")
                    if existing_score is not None:
                        try:
                            existing_cvss = float(existing_score)
                        except (ValueError, TypeError):
                            existing_cvss = 0.0
                    
                    new_cvss = 0.0
                    new_score = vuln_data.get("cvss_v3")
                    if new_score is not None:
                        try:
                            new_cvss = float(new_score)
                        except (ValueError, TypeError):
                            new_cvss = 0.0
                    
                    if new_cvss > existing_cvss:
                        all_vulnerabilities[cve_id] = vuln_data
                else:
                    all_vulnerabilities[cve_id] = vuln_data
        
        # Rate limiting between chunks (respect API limits)
        if i < len(date_ranges):  # Don't sleep after the last request
            if api_key:
                # With API key: 50 requests per 30 seconds, so wait at least 0.6 seconds
                sleep_time = 2.0  # Be conservative
            else:
                # Without API key: 5 requests per 30 seconds, so wait at least 6 seconds
                sleep_time = 7.0  # Be conservative
            
            logger.info(f"Waiting {sleep_time} seconds before next request (API rate limiting)...")
            time.sleep(sleep_time)
    
    # Sort final results by CVSS score
    sorted_vulns = {}
    try:
        # Create list of (cve_id, cvss) tuples for sorting
        vuln_scores = []
        for cve_id, vuln in all_vulnerabilities.items():
            cvss = 0.0
            cvss_str = vuln.get("cvss_v3")
            if cvss_str is not None:
                try:
                    cvss = float(cvss_str)
                except (ValueError, TypeError):
                    cvss = 0.0
            vuln_scores.append((cve_id, cvss))
        
        # Sort by CVSS (descending)
        vuln_scores.sort(key=lambda x: x[1], reverse=True)
        
        # Create sorted dictionary
        for cve_id, _ in vuln_scores:
            sorted_vulns[cve_id] = all_vulnerabilities[cve_id]
            
    except Exception as e:
        logger.error(f"Error sorting vulnerabilities: {str(e)}")
        sorted_vulns = all_vulnerabilities  # Use unsorted if sorting fails
    
    # Prepare final result
    result = {"vulnerabilities": sorted_vulns}
    
    logger.info(f"Total unique vulnerabilities found: {len(sorted_vulns)}")
    if min_cvss_score is not None:
        logger.info(f"Filtered to vulnerabilities with CVSS score >= {min_cvss_score}")
    
    return result

def get_cves_from_nvd_single_request(max_vulnerabilities=100, start_date=None, end_date=None, 
                                   cpe_dict=None, min_cvss_score=None, api_key=None, logger=None):
    """
    Fetch CVEs from NVD API for a single date range (original function logic).
    
    Parameters:
        max_vulnerabilities (int): Maximum number of vulnerabilities to fetch
        start_date (str): Starting date for vulnerability publication (YYYY-MM-DD)
        end_date (str): Ending date for vulnerability publication (YYYY-MM-DD)
        cpe_dict (dict): Dictionary mapping product names to CPE strings
        min_cvss_score (float): Minimum CVSS score to include
        api_key (str): NVD API key
        logger: Logger object
        
    Returns:
        dict: JSON object containing vulnerability data
    """
    # Initialize result dictionary
    result = {}
    
    # Set default dates if not provided
    if end_date is None:
        end_date = datetime.now().strftime("%Y-%m-%d")
    if start_date is None:
        # Default to 30 days ago if not specified
        start_date = (datetime.now() - timedelta(days=30)).strftime("%Y-%m-%d")
    
    # Format dates properly for the API
    start_timestamp = f"{start_date}T00:00:00.000"
    end_timestamp = f"{end_date}T23:59:59.999"
    
    # Initialize the vulnerabilities object with empty values
    vulnerabilities = {}
    # Default to empty dict if None
    if cpe_dict is None:
        cpe_dict = {'No specific product': ''}  # Empty string means no CPE filter
    elif isinstance(cpe_dict, str):
        # Convert single string to dict with generic product name
        cpe_dict = {'Generic Product': cpe_dict}
    
    # Ensure max_vulnerabilities has a reasonable value
    if not isinstance(max_vulnerabilities, int) or max_vulnerabilities <= 0:
        logger.warning(f"Invalid max_vulnerabilities: {max_vulnerabilities}, defaulting to 100")
        max_vulnerabilities = 100
    
    # Track total unique vulnerabilities across all products
    all_vulnerabilities = {}
    
    # Process each product and its CPE
    for product_name, cpe_name in cpe_dict.items():
        try:
            logger.info(f"Processing Product: {product_name}, CPE: {cpe_name if cpe_name else 'No specific CPE'}")
            
            # Make API request
            url = "https://services.nvd.nist.gov/rest/json/cves/2.0"
            params = {
                "resultsPerPage": min(100, max_vulnerabilities),
                "pubStartDate": start_timestamp,
                "pubEndDate": end_timestamp,
            }
            headers = {}
            
            if cpe_name:
                params["cpeName"] = cpe_name
                
            if api_key:
                headers["apiKey"] = api_key
                
            try:
                logger.info(f"Requesting CVEs from {start_timestamp} to {end_timestamp}" + 
                           (f" for CPE {cpe_name}" if cpe_name else ""))
                
                response = requests.get(url, headers=headers, params=params, timeout=30)
                logger.info(f"Request URL: {response.url}")
                logger.info(f"Status Code: {response.status_code}")
                
                if response.status_code != 200:
                    logger.error(f"API returned error status: {response.status_code}")
                    continue
                    
                data = response.json()
                vulnerabilities = data.get("vulnerabilities", [])
                
                if not vulnerabilities:
                    logger.warning(f"No vulnerabilities found for Product: {product_name}, CPE: {cpe_name if cpe_name else 'No specific CPE'}")
                    continue
                
                # Process each vulnerability
                for vuln in vulnerabilities:
                    cve_data = vuln.get("cve", {})
                    cve_id = cve_data.get("id", "Unknown")
                    
                    # Extract description
                    descriptions = cve_data.get("descriptions", [])
                    description = "No description available"
                    for desc in descriptions:
                        if desc.get("lang") == "en":
                            description = desc.get("value", "No description available")
                            break
                    
                    # Extract CVSS scores
                    metrics = cve_data.get("metrics", {})
                    cvss_v31 = metrics.get("cvssMetricV31", [])
                    cvss_v30 = metrics.get("cvssMetricV30", [])
                    
                    # Get CVSS v3 score (prefer v3.1, fall back to v3.0)
                    base_score_v3 = None
                    if cvss_v31:
                        base_score_v3 = cvss_v31[0].get("cvssData", {}).get("baseScore")
                    elif cvss_v30:
                        base_score_v3 = cvss_v30[0].get("cvssData", {}).get("baseScore")
                    
                    # Convert CVSS score to float for comparison
                    cvss_float = 0.0
                    if base_score_v3 is not None:
                        try:
                            cvss_float = float(base_score_v3)
                        except (ValueError, TypeError):
                            cvss_float = 0.0
                    
                    # Skip if below minimum CVSS score
                    if min_cvss_score is not None:
                        try:
                            min_score = float(min_cvss_score)
                            if cvss_float < min_score:
                                continue
                        except (ValueError, TypeError):
                            # If conversion fails, don't filter
                            pass
                    
                    # Extract dates
                    published = cve_data.get("published")
                    last_modified = cve_data.get("lastModified")
                    
                    # Extract references
                    references = cve_data.get("references", [])
                    reference_urls = [ref.get("url", "No URL") for ref in references]
                    
                    # Create a dictionary for this vulnerability
                    vuln_dict = {
                        "cve_id": cve_id,
                        "description": description,
                        "cvss_v3": base_score_v3,
                        "published": published,
                        "last_modified": last_modified,
                        "references": reference_urls,
                        "cpe": cpe_name if cpe_name else "none",
                        "product_name": product_name
                    }
                    
                    # Add to our results if it's new or has a higher CVSS score
                    if cve_id in all_vulnerabilities:
                        existing_cvss = 0.0
                        existing_score = all_vulnerabilities[cve_id].get("cvss_v3")
                        if existing_score is not None:
                            try:
                                existing_cvss = float(existing_score)
                            except (ValueError, TypeError):
                                existing_cvss = 0.0
                                
                        if cvss_float > existing_cvss:
                            all_vulnerabilities[cve_id] = vuln_dict
                    else:
                        all_vulnerabilities[cve_id] = vuln_dict
                
                logger.info(f"Found {len(vulnerabilities)} vulnerabilities for Product: {product_name}, CPE: {cve_name if cpe_name else 'No specific CPE'}")
                
            except requests.exceptions.RequestException as e:
                logger.error(f"Request failed: {str(e)}")
                continue
            except json.JSONDecodeError as e:
                logger.error(f"Failed to parse API response: {str(e)}")
                continue
            except Exception as e:
                logger.error(f"Error processing API response: {str(e)}")
                continue
            
            # Respect API rate limits between products
            time.sleep(1.5)
            
        except Exception as e:
            logger.error(f"Error processing Product: {product_name}, CPE: {cpe_name}: {str(e)}")
    
    # Add results to final output
    result["vulnerabilities"] = all_vulnerabilities
    
    return result