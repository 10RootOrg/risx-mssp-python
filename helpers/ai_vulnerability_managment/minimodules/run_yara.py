import json
import traceback
import time
import concurrent.futures
import math

# Assuming these are imported elsewhere in your code
import modules.Velociraptor.VelociraptorScript
from pyvelociraptor import api_pb2
from pyvelociraptor import api_pb2_grpc

def convert_yara_rules_to_string(yara_rules_dict, logger):
    """
    Converts a dictionary of YARA rules to a string format that can be used in Velociraptor.
    
    Args:
        yara_rules_dict (dict): Dictionary containing YARA rules keyed by CVE.
        logger: Logger object for logging messages.
    
    Returns:
        str: YARA rules in string format.
    """
    try:
        logger.info("Converting YARA rules to string format")
        yara_rules_text = ""
        
        # Process each CVE and its associated rules
        for cve_id, rules in yara_rules_dict.items():
            for rule_obj in rules:
                # Use provided rule name or default to "Rule_<CVE_ID>"
                rule_name = rule_obj.get("rule", f"Rule_{cve_id}")
                # Replace hyphens with underscores to ensure valid YARA rule names
                rule_name = rule_name.replace("-", "_")
                yara_rules_text += f"rule {rule_name} {{\n"
                
                # Add meta section
                meta = rule_obj.get("meta", {})
                if meta:
                    yara_rules_text += "  meta:\n"
                    for key, value in meta.items():
                        if isinstance(value, str):
                            yara_rules_text += f'    {key} = "{value}"\n'
                        else:
                            yara_rules_text += f"    {key} = {value}\n"
                
                # Add strings section
                strings = rule_obj.get("strings", [])
                if strings:
                    yara_rules_text += "  strings:\n"
                    for string_obj in strings:
                        string_id = string_obj.get("id", "$s")
                        string_value = string_obj.get("value", "")
                        # Escape quotes inside the string value
                        string_value = string_value.replace('"', '\\"')
                        yara_rules_text += f'    {string_id} = "{string_value}"\n'
                
                # Add condition section
                condition = rule_obj.get("condition", "all of them")
                yara_rules_text += "  condition:\n"
                yara_rules_text += f"    {condition}\n"
                
                # Close rule
                yara_rules_text += "}\n\n"
        
        logger.info(f"Successfully converted {len(yara_rules_dict)} CVE rules to YARA format")
        # Return the string with actual newlines
        return yara_rules_text.strip()
        
    except Exception as e:
        logger.error(f"Error converting YARA rules to string: {str(e)}")
        logger.error(traceback.format_exc())
        return ""

def format_arguments(params):
    """
    Format artifact parameters for use in Velociraptor query.
    
    Args:
        params (dict): Parameters to format
        
    Returns:
        str: Formatted parameters string
    """
    args = []
    for key, value in params.items():
        if isinstance(value, str):
            # Escape single quotes in string values
            escaped_value = value.replace("'", "\\'")
            args.append(f"{key}='{escaped_value}'")
        elif isinstance(value, bool):
            args.append(f"{key}={'TRUE' if value else 'FALSE'}")
        else:
            args.append(f"{key}={value}")
    
    return ", ".join(args)

def run_yara_file_scan(general_settings, yara_rules_dict, logger):
    """
    Launches Windows.Search.Yara artifact and waits for results.
    
    Args:
        general_settings: Dictionary containing configuration settings
        yara_rules_dict: Dictionary containing YARA rules
        logger: Logger object for logging messages
    
    Returns:
        tuple: (hunt_id, results_list)
    """
    try:
        # Convert YARA rules to string format
        yara_rule_string = convert_yara_rules_to_string(yara_rules_dict, logger)
        if not yara_rule_string:
            logger.error("Failed to convert YARA rules to string format")
            return ("", [])
            
        # Set artifact parameters
        artifact_name = "Windows.Search.Yara"
        
        # Set timeouts and resource limits
        timeout = general_settings.get("TimeForYaraScanInSeconds", 220)
        expire_time = general_settings.get("TimeForYaraScanInSeconds", 220)
        cpu_limit = general_settings.get("YaraCpuLimit", 90)
        max_bytes_uploaded = general_settings.get("YaraMaxBytesUploaded", 100000000)
        max_rows = general_settings.get("YaraMaxRows", 1000000)
        
        # Get retry settings - fixed 30 second interval
        retry_wait_seconds = 30
        max_attempts = general_settings.get("YaraMaxRetries", math.ceil(expire_time / retry_wait_seconds))
        
        # Set YARA specific parameters
        name_regex = general_settings.get("YaraNameRegex", "(exe|txt|dll|php)$")
        also_upload = general_settings.get("YaraAlsoUpload", True)
        
        logger.info(f"Starting Windows.Search.Yara artifact with {timeout}s timeout, {max_attempts} max retries, {retry_wait_seconds}s interval")
        
        # Create artifact parameters
        params = {
            "nameRegex": name_regex,
            "yaraRule": yara_rule_string,
            "alsoUpload": "Y" if also_upload else "N",
            "numberOfHits": 1,
            "contextBytes": 0
        }
        
        # Format arguments according to your format
        arguments = format_arguments(params)
        
        # Create hunt query using your format
        spec = f"dict(`{artifact_name}`=dict({arguments}))"
        query = f"LET collection = hunt(description='API Hunt:{artifact_name}', artifacts='{artifact_name}', spec={spec}, expires=now() + {expire_time}, timeout={timeout}, max_rows={max_rows}, max_bytes={max_bytes_uploaded}, cpu_limit={cpu_limit}) SELECT HuntId FROM collection"
        
        logger.info(f"Running query: {query}")
        
        # Setup connection
        channel = modules.Velociraptor.VelociraptorScript.setup_connection(logger)
        if not channel:
            logger.error("Failed to establish connection")
            return ("", [])
            
        stub = api_pb2_grpc.APIStub(channel)
        
        # Launch hunt
        hunt_id = None
        request = api_pb2.VQLCollectorArgs(Query=[api_pb2.VQLRequest(VQL=query)])
        
        for response in stub.Query(request):
            if response.Response and response.Response != "[]":
                parsed_json = json.loads(response.Response)
                hunt_id = parsed_json[0]["HuntId"]
                logger.info(f"Hunt started with ID: {hunt_id}")
                break
        
        if not hunt_id:
            logger.error("Failed to get hunt ID")
            channel.close()
            return ("", [])
        
        # Initial wait (30 seconds)
        logger.info(f"Waiting {retry_wait_seconds}s for hunt to collect initial data...")
        time.sleep(retry_wait_seconds)
        
        # Attempt to collect results
        all_rows = []
        
        for attempt in range(1, max_attempts + 1):
            logger.info(f"Collection attempt {attempt}/{max_attempts}")
            
            # Query for results
            results_query = f"SELECT * FROM hunt_results(hunt_id='{hunt_id}')"
            results_request = api_pb2.VQLCollectorArgs(
                Query=[api_pb2.VQLRequest(VQL=results_query)]
            )
            
            current_rows = []
            try:
                for response in stub.Query(results_request):
                    if response.Response:
                        rows = json.loads(response.Response)
                        if rows:
                            current_rows.extend(rows)
            except Exception as e:
                logger.warning(f"Error in collection attempt {attempt}: {str(e)}")
            
            if current_rows:
                logger.info(f"Successfully collected {len(current_rows)} rows of YARA file scan results")
                all_rows = current_rows
                break  # End the retry loop once we have results
                
            # Wait before next attempt - but don't wait after the last attempt
            if attempt < max_attempts:
                logger.info(f"Waiting {retry_wait_seconds}s before next collection attempt...")
                time.sleep(retry_wait_seconds)
        
        if not all_rows:
            logger.warning(f"Maximum collection attempts ({max_attempts}) reached without results")
        
        # Print out the results directly
        if all_rows:
            logger.info(f"File scan results for hunt {hunt_id}:")
            for i, row in enumerate(all_rows[:5]):  # Show first 5 for brevity
                logger.info(f"  Result {i+1}: {row}")
            if len(all_rows) > 5:
                logger.info(f"  ... and {len(all_rows) - 5} more results")
        
        channel.close()
        return (hunt_id, all_rows)
        
    except Exception as e:
        error_msg = f"Error running Windows.Search.Yara artifact: {str(e)}"
        logger.error(error_msg)
        logger.error(traceback.format_exc())
        return ("", [])

def run_yara_process_scan(general_settings, yara_rules_dict, logger):
    """
    Launches Windows.Detection.Yara.Process artifact and waits for results.
    
    Args:
        general_settings: Dictionary containing configuration settings
        yara_rules_dict: Dictionary containing YARA rules
        logger: Logger object for logging messages
    
    Returns:
        tuple: (hunt_id, results_list)
    """
    try:
        # Convert YARA rules to string format
        yara_rule_string = convert_yara_rules_to_string(yara_rules_dict, logger)
        if not yara_rule_string:
            logger.error("Failed to convert YARA rules to string format")
            return ("", [])
            
        # Set artifact parameters
        artifact_name = "Windows.Detection.Yara.Process"
        
        # Set timeouts and resource limits
        timeout = general_settings.get("TimeForYaraScanInSeconds", 220)
        expire_time = general_settings.get("TimeForYaraScanInSeconds", 220)
        cpu_limit = general_settings.get("YaraCpuLimit", 90)
        max_bytes_uploaded = general_settings.get("YaraMaxBytesUploaded", 100000000)
        max_rows = general_settings.get("YaraMaxRows", 1000000)
        
        # Get retry settings - fixed 30 second interval
        retry_wait_seconds = 30
        max_attempts = general_settings.get("YaraMaxRetries", math.ceil(expire_time / retry_wait_seconds))
        
        # Set YARA specific parameters
        process_regex = general_settings.get("YaraProcessRegex", ".")
        pid_regex = general_settings.get("YaraPidRegex", ".")
        upload_hits = general_settings.get("YaraUploadHits", True)
        
        logger.info(f"Starting Windows.Detection.Yara.Process artifact with {timeout}s timeout, {max_attempts} max retries, {retry_wait_seconds}s interval")
        
        # Create artifact parameters
        params = {
            "processRegex": process_regex,
            "pidRegex": pid_regex,
            "yaraRule": yara_rule_string,
            "uploadHits": "Y" if upload_hits else "N",
            "numberOfHits": 1,
            "contextBytes": 0
        }
        
        # Format arguments according to your format
        arguments = format_arguments(params)
        
        # Create hunt query using your format
        spec = f"dict(`{artifact_name}`=dict({arguments}))"
        query = f"LET collection = hunt(description='API Hunt:{artifact_name}', artifacts='{artifact_name}', spec={spec}, expires=now() + {expire_time}, timeout={timeout}, max_rows={max_rows}, max_bytes={max_bytes_uploaded}, cpu_limit={cpu_limit}) SELECT HuntId FROM collection"
        
        logger.info(f"Running query: {query}")
        
        # Setup connection
        channel = modules.Velociraptor.VelociraptorScript.setup_connection(logger)
        if not channel:
            logger.error("Failed to establish connection")
            return ("", [])
            
        stub = api_pb2_grpc.APIStub(channel)
        
        # Launch hunt
        hunt_id = None
        request = api_pb2.VQLCollectorArgs(Query=[api_pb2.VQLRequest(VQL=query)])
        
        for response in stub.Query(request):
            if response.Response and response.Response != "[]":
                parsed_json = json.loads(response.Response)
                hunt_id = parsed_json[0]["HuntId"]
                logger.info(f"Hunt started with ID: {hunt_id}")
                break
        
        if not hunt_id:
            logger.error("Failed to get hunt ID")
            channel.close()
            return ("", [])
        
        # Initial wait (30 seconds)
        logger.info(f"Waiting {retry_wait_seconds}s for hunt to collect initial data...")
        time.sleep(retry_wait_seconds)
        
        # Attempt to collect results
        all_rows = []
        
        for attempt in range(1, max_attempts + 1):
            logger.info(f"Collection attempt {attempt}/{max_attempts}")
            
            # Query for results
            results_query = f"SELECT * FROM hunt_results(hunt_id='{hunt_id}')"
            results_request = api_pb2.VQLCollectorArgs(
                Query=[api_pb2.VQLRequest(VQL=results_query)]
            )
            
            current_rows = []
            try:
                for response in stub.Query(results_request):
                    if response.Response:
                        rows = json.loads(response.Response)
                        if rows:
                            current_rows.extend(rows)
            except Exception as e:
                logger.warning(f"Error in collection attempt {attempt}: {str(e)}")
            
            if current_rows:
                logger.info(f"Successfully collected {len(current_rows)} rows of YARA process scan results")
                all_rows = current_rows
                break  # End the retry loop once we have results
                
            # Wait before next attempt - but don't wait after the last attempt
            if attempt < max_attempts:
                logger.info(f"Waiting {retry_wait_seconds}s before next collection attempt...")
                time.sleep(retry_wait_seconds)
        
        if not all_rows:
            logger.warning(f"Maximum collection attempts ({max_attempts}) reached without results")
        
        # Print out the results directly
        if all_rows:
            logger.info(f"Process scan results for hunt {hunt_id}:")
            for i, row in enumerate(all_rows[:5]):  # Show first 5 for brevity
                logger.info(f"  Result {i+1}: {row}")
            if len(all_rows) > 5:
                logger.info(f"  ... and {len(all_rows) - 5} more results")
        
        channel.close()
        return (hunt_id, all_rows)
        
    except Exception as e:
        error_msg = f"Error running Windows.Detection.Yara.Process artifact: {str(e)}"
        logger.error(error_msg)
        logger.error(traceback.format_exc())
        return ("", [])

def run_yara_scans(general_settings, yara_rules_dict, logger):
    """
    Launches both file and process YARA scans simultaneously and waits for results.
    
    Args:
        general_settings: Dictionary containing configuration settings
        yara_rules_dict: Dictionary containing YARA rules
        logger: Logger object for logging messages
    
    Returns:
        dict: Dictionary containing the hunt IDs and basic result information
    """
    try:
        logger.info("Starting YARA scans for both files and processes in parallel")
        
        # Fixed retry interval of 30 seconds
        retry_wait_seconds = 30
        
        # Get timeout setting (default to 220 seconds)
        timeout_seconds = general_settings.get("TimeForYaraScanInSeconds", 220)
        
        # Calculate retries based on expire time divided by 30 (rounded up)
        max_retries = math.ceil(timeout_seconds / retry_wait_seconds)
        
        logger.info(f"Using max_retries={max_retries}, retry_wait={retry_wait_seconds}s based on timeout={timeout_seconds}s")
        
        # Store retry settings in general_settings so they can be used by the scan functions
        general_settings["YaraMaxRetries"] = max_retries
        general_settings["YaraRetryWaitSeconds"] = retry_wait_seconds
        
        # Use ThreadPoolExecutor to run both scans in parallel
        with concurrent.futures.ThreadPoolExecutor(max_workers=2) as executor:
            # Submit both tasks
            file_scan_future = executor.submit(run_yara_file_scan, general_settings, yara_rules_dict, logger)
            process_scan_future = executor.submit(run_yara_process_scan, general_settings, yara_rules_dict, logger)
            
            # Wait for both tasks to complete
            file_hunt_id, file_results = file_scan_future.result()
            process_hunt_id, process_results = process_scan_future.result()
        
        # Combine results into a simple report
        all_results = {
            "file_scan_hunt_id": file_hunt_id,
            "process_scan_hunt_id": process_hunt_id,
            "total_file_matches": len(file_results),
            "total_process_matches": len(process_results)
        }
        
        # Print a summary
        logger.info("YARA scan summary:")
        logger.info(f"  File scan (hunt ID: {file_hunt_id}): Found {len(file_results)} matches")
        logger.info(f"  Process scan (hunt ID: {process_hunt_id}): Found {len(process_results)} matches")
        
        return all_results
        
    except Exception as e:
        logger.error(f"Error running parallel YARA scans: {str(e)}")
        logger.error(traceback.format_exc())
        return {
            "file_scan_hunt_id": "", 
            "process_scan_hunt_id": "", 
            "total_file_matches": 0, 
            "total_process_matches": 0
        }